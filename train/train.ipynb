{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress Tensorflow verbose prints\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from form_train_data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "data_path = Path.cwd() / 'data'\n",
    "train_dataset_path = data_path / 'CASIA-WebFace-112x96'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "Loading test data\n"
     ]
    }
   ],
   "source": [
    "print(\"CASIA pairs for training\")\n",
    "print(\"LFW pairs for testing\")\n",
    "casia_pairs, lfw_pairs = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle casia_list\n"
     ]
    }
   ],
   "source": [
    "print(\"shuffle casia list\")\n",
    "np.random.shuffle(casia_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to pandas dataframe\n",
      "test dataframe\n",
      "                                                  fileL  \\\n",
      "0                    Abel_Pacheco\\Abel_Pacheco_0001.jpg   \n",
      "1                Akhmed_Zakayev\\Akhmed_Zakayev_0001.jpg   \n",
      "2                Akhmed_Zakayev\\Akhmed_Zakayev_0002.jpg   \n",
      "3                  Amber_Tamblyn\\Amber_Tamblyn_0001.jpg   \n",
      "4                Angela_Bassett\\Angela_Bassett_0001.jpg   \n",
      "...                                                 ...   \n",
      "5597                     Scott_Wolf\\Scott_Wolf_0002.jpg   \n",
      "5598  Sergei_Alexandrovitch_Ordzhonikidze\\Sergei_Ale...   \n",
      "5599                     Shane_Loux\\Shane_Loux_0001.jpg   \n",
      "5600                 Shawn_Marion\\Shawn_Marion_0001.jpg   \n",
      "5601     Slobodan_Milosevic\\Slobodan_Milosevic_0002.jpg   \n",
      "\n",
      "                                       fileR  flag  \n",
      "0         Abel_Pacheco\\Abel_Pacheco_0004.jpg     1  \n",
      "1     Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "2     Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "3       Amber_Tamblyn\\Amber_Tamblyn_0002.jpg     1  \n",
      "4     Angela_Bassett\\Angela_Bassett_0005.jpg     1  \n",
      "...                                      ...   ...  \n",
      "5597    Troy_Polamalu\\Troy_Polamalu_0001.jpg     0  \n",
      "5598      Yolanda_King\\Yolanda_King_0001.jpg     0  \n",
      "5599      Val_Ackerman\\Val_Ackerman_0001.jpg     0  \n",
      "5600    Shirley_Jones\\Shirley_Jones_0001.jpg     0  \n",
      "5601                  Sok_An\\Sok_An_0001.jpg     0  \n",
      "\n",
      "[5602 rows x 3 columns]\n",
      "\n",
      "train dataframe\n",
      "                    fileL            fileR  flag\n",
      "0         0633604\\137.jpg  0633604\\187.jpg     1\n",
      "1         0579953\\021.jpg  1952233\\031.jpg     0\n",
      "2         1466205\\009.jpg  1466205\\011.jpg     1\n",
      "3         0005447\\099.jpg  0005447\\144.jpg     1\n",
      "4         0385293\\105.jpg  0385293\\143.jpg     1\n",
      "...                   ...              ...   ...\n",
      "47006103  0424060\\017.jpg  0424060\\132.jpg     1\n",
      "47006104  1936361\\004.jpg  1936361\\008.jpg     1\n",
      "47006105  1842439\\073.jpg  1842439\\148.jpg     1\n",
      "47006106  0570860\\003.jpg  0095746\\037.jpg     0\n",
      "47006107  0736622\\130.jpg  0773056\\041.jpg     0\n",
      "\n",
      "[47006108 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"convert to pandas dataframe\")\n",
    "lfw_list = lfw_pairs.tolist()\n",
    "casia_list = casia_pairs.tolist()\n",
    "test_dataframe = pd.DataFrame(lfw_list)\n",
    "train_dataframe = pd.DataFrame(casia_list) # takes long time\n",
    "\n",
    "print(\"test dataframe\")\n",
    "print(test_dataframe)\n",
    "print()\n",
    "print(\"train dataframe\")\n",
    "print(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe['flag'] = train_dataframe['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myphi(x,m):\n",
    "#     x = x * m\n",
    "#     return 1 - x**2/math.factorial(2) + x**4/math.factorial(4) - x**6/math.factorial(6) + x**8/math.factorial(8) - x**9/math.factorial(9)\n",
    "\n",
    "# class MarginInnerProductLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, in_features, out_features, m=4, phiflag=True):\n",
    "#         super(MarginInnerProductLayer, self).__init__()\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.phiflag = phiflag\n",
    "#         self.m = m\n",
    "#         self.mlambda = [\n",
    "#             lambda x: x**0,\n",
    "#             lambda x: x**1,\n",
    "#             lambda x: 2*x**2-1,\n",
    "#             lambda x: 4*x**3-3*x,\n",
    "#             lambda x: 8*x**4-8*x**2+1,\n",
    "#             lambda x: 16*x**5-20*x**3+5*x\n",
    "#         ]\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         #Create a trainable weight variable for this layer.\n",
    "#         self.kernel = self.add_weight(name='fc6', shape=(self.in_features, self.out_features), initializer='uniform', trainable=True)\n",
    "#         super(MarginInnerProductLayer, self).build(input_shape)\n",
    "\n",
    "#     def call(self, x):    \n",
    "#         x1 = x\n",
    "#         w1 = self.kernel\n",
    "\n",
    "#         x2 = K.pow(x1,2)\n",
    "#         x2 = K.sum(x2,1)\n",
    "#         x2 = K.pow(x2,0.5)\n",
    "\n",
    "#         w2 = K.pow(w1,2)\n",
    "#         w2 = K.sum(w2,0)\n",
    "#         w2 = K.pow(w2,0.5)\n",
    "\n",
    "#         x1 = K.variable(value=x1)\n",
    "#         w1 = K.variable(value=w1)\n",
    "\n",
    "#         cos_theta = K.dot(x1,w1)\n",
    "#         cos_theta = cos_theta / K.reshape(x2,(-1,1)) / K.reshape(w2,(1,-1))\n",
    "#         cos_theta = K.clip(cos_theta, -1, 1)\n",
    "\n",
    "#         if self.phiflag:\n",
    "            \n",
    "#             cos_m_theta = self.mlambda[self.m](cos_theta)\n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             k = math.floor(self.m*theta/3.14159265)\n",
    "#             n_one = k*0.0 - 1\n",
    "#             phi_theta = (n_one**k) * cos_m_theta - 2*k\n",
    "\n",
    "#         else:\n",
    "            \n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             phi_theta = myphi(theta,self.m)\n",
    "#             phi_theta = K.clip(phi_theta, -1*self.m, 1)\n",
    "\n",
    "#         cos_theta = cos_theta * K.reshape(x2,(-1,1))\n",
    "#         phi_theta = phi_theta * K.reshape(x2,(-1,1))\n",
    "#         output = (cos_theta,phi_theta)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.out_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Add, Activation, PReLU, Dense, Input, ZeroPadding2D, Lambda, GlobalAveragePooling2D, Dot \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CosineSimilarity\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def conv_3_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=2, padding='valid', kernel_initializer='glorot_uniform')(x)\n",
    "    r1 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r1)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r2 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r2)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r3 = PReLU()(x)\n",
    "\n",
    "    x = Add()([r1, r3])\n",
    "    return x \n",
    "\n",
    "def conv_2_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Add()([input, x])\n",
    "    return x\n",
    "\n",
    "def sphereface20(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = conv_3_block(input, 64)\n",
    "    x = conv_3_block(x, 128)\n",
    "    x = conv_2_block(x, 128)\n",
    "    x = conv_3_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_3_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "# https://keras.io/examples/mnist_siamese/\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# https://stackoverflow.com/questions/51003027/computing-cosine-similarity-between-two-tensors-in-keras\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "\n",
    "# network definition\n",
    "input_shape = (112, 96, 3)\n",
    "base_network = sphereface20(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_path = str(Path.cwd().parent / 'models' / 'sphereface_20_keras' / 'sphereface_20.json')\n",
    "model_json = base_network.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 112, 96, 3)] input_26\n",
      "(None, 114, 98, 3) zero_padding2d_260\n",
      "(None, 56, 48, 64) conv2d_260\n",
      "(None, 56, 48, 64) p_re_lu_260\n",
      "(None, 58, 50, 64) zero_padding2d_261\n",
      "(None, 56, 48, 64) conv2d_261\n",
      "(None, 56, 48, 64) p_re_lu_261\n",
      "(None, 58, 50, 64) zero_padding2d_262\n",
      "(None, 56, 48, 64) conv2d_262\n",
      "(None, 56, 48, 64) p_re_lu_262\n",
      "(None, 56, 48, 64) add_104\n",
      "(None, 58, 50, 64) zero_padding2d_263\n",
      "(None, 28, 24, 128) conv2d_263\n",
      "(None, 28, 24, 128) p_re_lu_263\n",
      "(None, 30, 26, 128) zero_padding2d_264\n",
      "(None, 28, 24, 128) conv2d_264\n",
      "(None, 28, 24, 128) p_re_lu_264\n",
      "(None, 30, 26, 128) zero_padding2d_265\n",
      "(None, 28, 24, 128) conv2d_265\n",
      "(None, 28, 24, 128) p_re_lu_265\n",
      "(None, 28, 24, 128) add_105\n",
      "(None, 30, 26, 128) zero_padding2d_266\n",
      "(None, 28, 24, 128) conv2d_266\n",
      "(None, 28, 24, 128) p_re_lu_266\n",
      "(None, 30, 26, 128) zero_padding2d_267\n",
      "(None, 28, 24, 128) conv2d_267\n",
      "(None, 28, 24, 128) p_re_lu_267\n",
      "(None, 28, 24, 128) add_106\n",
      "(None, 30, 26, 128) zero_padding2d_268\n",
      "(None, 14, 12, 256) conv2d_268\n",
      "(None, 14, 12, 256) p_re_lu_268\n",
      "(None, 16, 14, 256) zero_padding2d_269\n",
      "(None, 14, 12, 256) conv2d_269\n",
      "(None, 14, 12, 256) p_re_lu_269\n",
      "(None, 16, 14, 256) zero_padding2d_270\n",
      "(None, 14, 12, 256) conv2d_270\n",
      "(None, 14, 12, 256) p_re_lu_270\n",
      "(None, 14, 12, 256) add_107\n",
      "(None, 16, 14, 256) zero_padding2d_271\n",
      "(None, 14, 12, 256) conv2d_271\n",
      "(None, 14, 12, 256) p_re_lu_271\n",
      "(None, 16, 14, 256) zero_padding2d_272\n",
      "(None, 14, 12, 256) conv2d_272\n",
      "(None, 14, 12, 256) p_re_lu_272\n",
      "(None, 14, 12, 256) add_108\n",
      "(None, 16, 14, 256) zero_padding2d_273\n",
      "(None, 14, 12, 256) conv2d_273\n",
      "(None, 14, 12, 256) p_re_lu_273\n",
      "(None, 16, 14, 256) zero_padding2d_274\n",
      "(None, 14, 12, 256) conv2d_274\n",
      "(None, 14, 12, 256) p_re_lu_274\n",
      "(None, 14, 12, 256) add_109\n",
      "(None, 16, 14, 256) zero_padding2d_275\n",
      "(None, 14, 12, 256) conv2d_275\n",
      "(None, 14, 12, 256) p_re_lu_275\n",
      "(None, 16, 14, 256) zero_padding2d_276\n",
      "(None, 14, 12, 256) conv2d_276\n",
      "(None, 14, 12, 256) p_re_lu_276\n",
      "(None, 14, 12, 256) add_110\n",
      "(None, 16, 14, 256) zero_padding2d_277\n",
      "(None, 7, 6, 512) conv2d_277\n",
      "(None, 7, 6, 512) p_re_lu_277\n",
      "(None, 9, 8, 512) zero_padding2d_278\n",
      "(None, 7, 6, 512) conv2d_278\n",
      "(None, 7, 6, 512) p_re_lu_278\n",
      "(None, 9, 8, 512) zero_padding2d_279\n",
      "(None, 7, 6, 512) conv2d_279\n",
      "(None, 7, 6, 512) p_re_lu_279\n",
      "(None, 7, 6, 512) add_111\n",
      "(None, 512) global_average_pooling2d_2\n",
      "(None, 512) dense_10\n",
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000002A48B32E988>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A614576108>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CC6308>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CC8748>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CC8588>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CD0748>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CD5908>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CD8908>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CE3048>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CE4D88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4F3CE7048>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CF0DC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CFC488>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CFCD48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CFF848>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3B3A88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3B9408>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3C1088>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3C7B48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3CE908>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A3D0708>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3DCD88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3DE388>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3E0EC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3E0D48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3EA988>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3F1A88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A3F3388>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3FB2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A400CC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A407D48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A407CC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A40E1C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A413888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A419E48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A41EC48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A426D48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A426B88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A42FC88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A436848>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A438D88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A43B348>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A43FE08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A448F48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A449888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A454D08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A458F48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A45BD88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A45F1C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A464C48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A46BA08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A46F808>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A47BB48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A47D4C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A482A88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A47FF88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A489A88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A48F848>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A491648>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A499348>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A49CE08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4A3E48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A4A3E08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A4AF5C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4B4A08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A4BCB48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A4B6788>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4C5F08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A4C5D08>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000002A50A4CD648>, <tensorflow.python.keras.layers.core.Dense object at 0x000002A50A4D6048>]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"sparse\"\n",
    "    generator = ImageDataGenerator(preprocessing_function=preprocess_image,\n",
    "                                   validation_split=0.01)\n",
    "    \n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    \n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net: \"code/sphereface_model.prototxt\"\n",
    "# #test_iter: 100 \n",
    "# #test_interval: 2000\n",
    "\n",
    "# base_lr: 0.1\n",
    "# lr_policy: \"multistep\"\n",
    "# gamma: 0.1\n",
    "\n",
    "# stepvalue: 16000\n",
    "# stepvalue: 24000\n",
    "# stepvalue: 28000\n",
    "# max_iter: 28000\n",
    "\n",
    "# display: 100\n",
    "# momentum: 0.9\n",
    "# weight_decay: 0.0005\n",
    "# #snapshot: 1000\n",
    "# snapshot_prefix: \"result/sphereface_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "# optimizer_ = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "optimizer_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "# loss_ = custom_loss\n",
    "# loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer_, metrics=[accuracy])\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.05 GiB for an array with shape (3, 47006108) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-dafa4398c9c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://github.com/keras-team/keras/issues/10855\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    828\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-994ff90ef5fb>\u001b[0m in \u001b[0;36mtrain_generator\u001b[1;34m(train_dataframe, batch_size_)\u001b[0m\n\u001b[0;32m     24\u001b[0m                              \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_mode_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                              \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                              target_size=(112, 96))\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     train_generator_X2 = generator.flow_from_dataframe(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m             \u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m         )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    122\u001b[0m                                                             \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                                             interpolation)\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5809\u001b[0m         \"\"\"\n\u001b[1;32m-> 5810\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5811\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"copy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.05 GiB for an array with shape (3, 47006108) and data type object"
     ]
    }
   ],
   "source": [
    "batch_size_ = 64\n",
    "epochs_ = 2\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "hist = model.fit_generator(train_generator(train_dataframe, batch_size_), epochs=epochs_, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casia_pairs_short = []\n",
    "lfw_pairs_short = []\n",
    "\n",
    "i_0 = 0 # number of pairs with 'flag' == 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(casia_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "\n",
    "i_0 = 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(lfw_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "        \n",
    "# convert to pandas dataframe\n",
    "test_dataframe_short = pd.DataFrame(lfw_list_short)\n",
    "train_dataframe_short = pd.DataFrame(casia_list_short) # takes long time\n",
    "\n",
    "print(\"short test dataframe\")\n",
    "print(test_dataframe_short)\n",
    "print()\n",
    "print(\"short train dataframe\")\n",
    "print(train_dataframe_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe_short['flag'] = train_dataframe_short['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fileL': '0000045\\\\001.jpg', 'fileR': '0000045\\\\002.jpg', 'flag': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lfw_pairs[0]\n",
    "casia_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator(train_dataframe, batch_size):\n",
    "    generator = ImageDataGenerator(\n",
    "                             fill_mode=\"nearest\",\n",
    "                             cval=0.0,\n",
    "                             horizontal_flip=False,\n",
    "                             vertical_flip=False,\n",
    "                             rescale=None,\n",
    "                             preprocessing_function=preprocess_image,\n",
    "                             data_format=None,\n",
    "                             validation_split=0.001,\n",
    "                             dtype=None)\n",
    "    \n",
    "    valid_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))  \n",
    "\n",
    "    valid_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = valid_generator_X1.next()\n",
    "        X2i = valid_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n",
    "\n",
    "\n",
    "\n",
    "def test_generator(test_dataframe, batch_size):\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                             preprocessing_function=preprocess_image) \n",
    "    test_generator_X1 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(data_path.parent.parent / 'test' / 'data' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "\n",
    "    test_generator_X2 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(data_path.parent.parent / 'test' / 'data' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "    while True:\n",
    "        X1i = test_generator_X1.next()\n",
    "        X2i = test_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2data(dt, dataset_path):\n",
    "    fileL_paths = list(map(lambda x: str(dataset_path / x), dt['fileL'].to_list()))\n",
    "    fileR_paths = list(map(lambda x: str(dataset_path / x), dt['fileR'].to_list()))\n",
    "    Y = list(map(lambda x: int(x), dt['flag'].to_list()))\n",
    "    \n",
    "    X1 = []\n",
    "    for path in fileL_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X1.append(image)\n",
    "    \n",
    "    X2 = []   \n",
    "    for path in fileR_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X2.append(image)\n",
    "    \n",
    "    return [X1, X2], Y\n",
    "\n",
    "X, Y = dataframe2data(train_dataframe, train_dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 96, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27e6b65d908>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X[0][0].shape)\n",
    "# print(X[0][0])\n",
    "plt.imshow(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\Face_Identification\\sphereface_keras\\train\\data\\CASIA-WebFace-112x96\\0000045\\001.jpg\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_path / casia_pairs[0]['fileL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                              | 0/1200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▌                              | 124/1200 [00:00<00:00, 1234.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|███████                           | 248/1200 [00:00<00:00, 1232.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|██████████▌                       | 371/1200 [00:00<00:00, 1229.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|██████████████                    | 495/1200 [00:00<00:00, 1230.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████████████████▌                | 619/1200 [00:00<00:00, 1232.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████████████████████▋              | 722/1200 [00:04<00:05, 90.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|███████████████████████▊            | 795/1200 [00:08<00:09, 41.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|█████████████████████████▍          | 847/1200 [00:10<00:11, 31.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|██████████████████████████▌         | 884/1200 [00:12<00:12, 25.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████████████████████████▎        | 911/1200 [00:14<00:12, 22.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████████████████████████▉        | 930/1200 [00:15<00:12, 21.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|████████████████████████████▎       | 944/1200 [00:15<00:12, 20.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████████████████████████▋       | 955/1200 [00:16<00:12, 20.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████████████████████████▉       | 963/1200 [00:16<00:11, 20.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|█████████████████████████████       | 970/1200 [00:17<00:11, 20.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|█████████████████████████████▎      | 975/1200 [00:17<00:11, 20.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|█████████████████████████████▎      | 979/1200 [00:17<00:09, 22.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|█████████████████████████████▍      | 983/1200 [00:17<00:09, 22.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|█████████████████████████████▌      | 987/1200 [00:18<00:09, 22.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|█████████████████████████████▋      | 990/1200 [00:18<00:08, 24.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|█████████████████████████████▊      | 993/1200 [00:18<00:08, 23.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|█████████████████████████████▉      | 996/1200 [00:18<00:10, 19.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|█████████████████████████████▉      | 999/1200 [00:18<00:10, 18.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|█████████████████████████████▏     | 1002/1200 [00:18<00:10, 18.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|█████████████████████████████▎     | 1005/1200 [00:18<00:10, 18.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|█████████████████████████████▍     | 1008/1200 [00:19<00:10, 19.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|█████████████████████████████▍     | 1011/1200 [00:19<00:10, 18.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|█████████████████████████████▌     | 1013/1200 [00:19<00:11, 16.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████▋     | 1016/1200 [00:19<00:10, 17.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████▋     | 1019/1200 [00:19<00:10, 17.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████▊     | 1022/1200 [00:19<00:09, 18.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████▉     | 1025/1200 [00:20<00:08, 20.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████▉     | 1028/1200 [00:20<00:09, 18.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|██████████████████████████████     | 1030/1200 [00:20<00:09, 18.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|██████████████████████████████▏    | 1033/1200 [00:20<00:08, 18.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|██████████████████████████████▏    | 1036/1200 [00:20<00:07, 20.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|██████████████████████████████▎    | 1039/1200 [00:20<00:07, 21.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|██████████████████████████████▍    | 1042/1200 [00:20<00:07, 20.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|██████████████████████████████▍    | 1045/1200 [00:21<00:07, 20.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|██████████████████████████████▌    | 1048/1200 [00:21<00:07, 21.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|██████████████████████████████▋    | 1051/1200 [00:21<00:07, 21.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|██████████████████████████████▋    | 1054/1200 [00:21<00:06, 21.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|██████████████████████████████▊    | 1057/1200 [00:21<00:07, 19.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|██████████████████████████████▉    | 1060/1200 [00:21<00:07, 17.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|██████████████████████████████▉    | 1062/1200 [00:21<00:08, 15.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|███████████████████████████████    | 1064/1200 [00:22<00:08, 16.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|███████████████████████████████    | 1066/1200 [00:22<00:07, 17.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|███████████████████████████████▏   | 1069/1200 [00:22<00:07, 17.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|███████████████████████████████▏   | 1071/1200 [00:22<00:07, 17.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|███████████████████████████████▎   | 1073/1200 [00:22<00:07, 17.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████▎   | 1075/1200 [00:22<00:07, 15.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████▍   | 1078/1200 [00:22<00:07, 16.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████▌   | 1081/1200 [00:23<00:06, 17.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████▌   | 1083/1200 [00:23<00:07, 16.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████▋   | 1086/1200 [00:23<00:06, 17.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████▋   | 1088/1200 [00:23<00:06, 16.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████▊   | 1090/1200 [00:23<00:06, 16.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████▊   | 1092/1200 [00:23<00:06, 16.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████▉   | 1095/1200 [00:23<00:05, 17.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████▉   | 1097/1200 [00:24<00:06, 16.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|████████████████████████████████   | 1100/1200 [00:24<00:05, 18.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|████████████████████████████████▏  | 1103/1200 [00:24<00:04, 20.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|████████████████████████████████▎  | 1106/1200 [00:24<00:04, 19.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|████████████████████████████████▎  | 1109/1200 [00:24<00:04, 20.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████▍  | 1112/1200 [00:24<00:04, 20.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████▌  | 1115/1200 [00:24<00:04, 17.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████▌  | 1118/1200 [00:25<00:04, 18.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████▋  | 1120/1200 [00:25<00:04, 18.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████▊  | 1123/1200 [00:25<00:03, 19.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████▊  | 1125/1200 [00:25<00:04, 18.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████▊  | 1127/1200 [00:25<00:04, 17.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████▉  | 1129/1200 [00:25<00:04, 16.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████████████████████████████  | 1132/1200 [00:25<00:03, 18.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████████████████████████████  | 1134/1200 [00:25<00:03, 18.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████▏ | 1136/1200 [00:26<00:03, 18.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████▏ | 1139/1200 [00:26<00:02, 20.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████▎ | 1142/1200 [00:26<00:02, 20.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████▍ | 1145/1200 [00:26<00:02, 21.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████▍ | 1148/1200 [00:26<00:02, 22.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████▌ | 1151/1200 [00:26<00:02, 18.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████▋ | 1154/1200 [00:26<00:02, 18.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████▋ | 1157/1200 [00:27<00:02, 19.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████▊ | 1160/1200 [00:27<00:02, 19.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████▉ | 1163/1200 [00:27<00:01, 19.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|██████████████████████████████████ | 1166/1200 [00:27<00:01, 17.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|██████████████████████████████████ | 1169/1200 [00:27<00:01, 18.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████▏| 1171/1200 [00:27<00:01, 16.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████▏| 1174/1200 [00:27<00:01, 18.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████▎| 1177/1200 [00:28<00:01, 19.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████▍| 1180/1200 [00:28<00:00, 21.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████▌| 1183/1200 [00:28<00:00, 21.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████▌| 1186/1200 [00:28<00:00, 21.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████▋| 1189/1200 [00:28<00:00, 20.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████▊| 1192/1200 [00:28<00:00, 22.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████▊| 1195/1200 [00:28<00:00, 21.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████| 1200/1200 [00:29<00:00, 41.11it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "Y = []\n",
    "for pair in tqdm(casia_pairs_short):\n",
    "    imageL = cv2.imread(str(train_dataset_path / pair['fileL']))\n",
    "    imageL = preprocess_image(imageL)\n",
    "    imageR = cv2.imread(str(train_dataset_path / pair['fileR']))\n",
    "    imageR = preprocess_image(imageR)\n",
    "    X1.append(imageL)\n",
    "    X2.append(imageR)\n",
    "    Y.append(pair['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 112, 96, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.asarray(X1)\n",
    "X2 = np.asarray(X2)\n",
    "Y = np.asarray(Y)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "batch_size_ = 64\n",
    "epochs_ = 6\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "rms_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])\n",
    "# model.compile(loss=contrastive_loss, optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "def generator_two_img(X1, X2, y, batch_size):\n",
    "    generator = ImageDataGenerator()\n",
    "    \n",
    "    genX1 = generator.flow(X1, y,  batch_size=batch_size, seed=1)\n",
    "    genX2 = generator.flow(X2, y, batch_size=batch_size, seed=1)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/18 [==============================] - 125s 7s/step - loss: 0.2686 - accuracy: 0.6094\n",
      "Epoch 2/2\n",
      "18/18 [==============================] - 122s 7s/step - loss: 0.3000 - accuracy: 0.5770\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator_two_img(X1, X2, Y, batch_size_),\n",
    "                           steps_per_epoch=len(X1)//batch_size_, \n",
    "                           epochs=epochs_,\n",
    "                           callbacks = None, \n",
    "                           shuffle=True)\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "# hist = model.fit(X, Y, epochs=epochs_, batch_size=batch_size_)\n",
    "# hist = model.fit(x=X, \n",
    "#                  y=Y, \n",
    "#                  batch_size=batch_size_, \n",
    "#                  epochs=epochs_, \n",
    "#                  verbose=1, \n",
    "#                  callbacks=None,\n",
    "#                  validation_split=0.01, \n",
    "#                  validation_data=None, \n",
    "#                  shuffle=True, \n",
    "#                  class_weight=None,\n",
    "#                  sample_weight=None, \n",
    "#                  initial_epoch=0, \n",
    "#                  steps_per_epoch=None,\n",
    "#                  validation_steps=None, \n",
    "#                  validation_batch_size=None, \n",
    "#                  validation_freq=1,\n",
    "#                  max_queue_size=10, \n",
    "#                  workers=1, \n",
    "#                  use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 96, 3), (112, 96, 3), 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0].shape, X2[0].shape, Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 96, 3) (1, 112, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "X1_test = np.expand_dims(X1[0], 0)\n",
    "X2_test = np.expand_dims(X2[0], 0)\n",
    "print(X1_test.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 6, 512)\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "prediction = base_network.predict(X1_test)\n",
    "print(prediction.shape)\n",
    "# print(prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 112, 96, 3)] input_12\n",
      "(None, 114, 98, 3) zero_padding2d_100\n",
      "(None, 56, 48, 64) conv2d_100\n",
      "(None, 56, 48, 64) p_re_lu_100\n",
      "(None, 58, 50, 64) zero_padding2d_101\n",
      "(None, 56, 48, 64) conv2d_101\n",
      "(None, 56, 48, 64) p_re_lu_101\n",
      "(None, 58, 50, 64) zero_padding2d_102\n",
      "(None, 56, 48, 64) conv2d_102\n",
      "(None, 56, 48, 64) p_re_lu_102\n",
      "(None, 56, 48, 64) add_40\n",
      "(None, 58, 50, 64) zero_padding2d_103\n",
      "(None, 28, 24, 128) conv2d_103\n",
      "(None, 28, 24, 128) p_re_lu_103\n",
      "(None, 30, 26, 128) zero_padding2d_104\n",
      "(None, 28, 24, 128) conv2d_104\n",
      "(None, 28, 24, 128) p_re_lu_104\n",
      "(None, 30, 26, 128) zero_padding2d_105\n",
      "(None, 28, 24, 128) conv2d_105\n",
      "(None, 28, 24, 128) p_re_lu_105\n",
      "(None, 28, 24, 128) add_41\n",
      "(None, 30, 26, 128) zero_padding2d_106\n",
      "(None, 28, 24, 128) conv2d_106\n",
      "(None, 28, 24, 128) p_re_lu_106\n",
      "(None, 30, 26, 128) zero_padding2d_107\n",
      "(None, 28, 24, 128) conv2d_107\n",
      "(None, 28, 24, 128) p_re_lu_107\n",
      "(None, 28, 24, 128) add_42\n",
      "(None, 30, 26, 128) zero_padding2d_108\n",
      "(None, 14, 12, 256) conv2d_108\n",
      "(None, 14, 12, 256) p_re_lu_108\n",
      "(None, 16, 14, 256) zero_padding2d_109\n",
      "(None, 14, 12, 256) conv2d_109\n",
      "(None, 14, 12, 256) p_re_lu_109\n",
      "(None, 16, 14, 256) zero_padding2d_110\n",
      "(None, 14, 12, 256) conv2d_110\n",
      "(None, 14, 12, 256) p_re_lu_110\n",
      "(None, 14, 12, 256) add_43\n",
      "(None, 16, 14, 256) zero_padding2d_111\n",
      "(None, 14, 12, 256) conv2d_111\n",
      "(None, 14, 12, 256) p_re_lu_111\n",
      "(None, 16, 14, 256) zero_padding2d_112\n",
      "(None, 14, 12, 256) conv2d_112\n",
      "(None, 14, 12, 256) p_re_lu_112\n",
      "(None, 14, 12, 256) add_44\n",
      "(None, 16, 14, 256) zero_padding2d_113\n",
      "(None, 14, 12, 256) conv2d_113\n",
      "(None, 14, 12, 256) p_re_lu_113\n",
      "(None, 16, 14, 256) zero_padding2d_114\n",
      "(None, 14, 12, 256) conv2d_114\n",
      "(None, 14, 12, 256) p_re_lu_114\n",
      "(None, 14, 12, 256) add_45\n",
      "(None, 16, 14, 256) zero_padding2d_115\n",
      "(None, 14, 12, 256) conv2d_115\n",
      "(None, 14, 12, 256) p_re_lu_115\n",
      "(None, 16, 14, 256) zero_padding2d_116\n",
      "(None, 14, 12, 256) conv2d_116\n",
      "(None, 14, 12, 256) p_re_lu_116\n",
      "(None, 14, 12, 256) add_46\n",
      "(None, 16, 14, 256) zero_padding2d_117\n",
      "(None, 7, 6, 512) conv2d_117\n",
      "(None, 7, 6, 512) p_re_lu_117\n",
      "(None, 9, 8, 512) zero_padding2d_118\n",
      "(None, 7, 6, 512) conv2d_118\n",
      "(None, 7, 6, 512) p_re_lu_118\n",
      "(None, 9, 8, 512) zero_padding2d_119\n",
      "(None, 7, 6, 512) conv2d_119\n",
      "(None, 7, 6, 512) p_re_lu_119\n",
      "(None, 7, 6, 512) add_47\n",
      "(None, 7, 6, 512) average_pooling2d_1\n",
      "(None, 7, 6, 512) dense_3\n",
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000002A48E552D88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5356FE108>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488E676C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48E6EFF88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A48E6EFDC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A48E6E40C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48E70AE08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A53572B208>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535727CC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A535700A88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A535723888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A535709BC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A53577D388>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A53577CD08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A53577A148>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535787B88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A535792F08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A535797E88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357A3608>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357AA488>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A5357AE208>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357ABD08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357A2788>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357A2B48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357937C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535773148>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357BEC48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A5357C20C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357D1BC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357DF488>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357DFBC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357E5B88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357E0F88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357C5F48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357C5F08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357C4A08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357D4B08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880A16C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880AE2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880B8F08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880BDE48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880C6F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880CB748>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880D8588>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880D9488>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880AD0C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880AAD88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880C4C88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880D7EC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880E0908>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880EAD88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880EC508>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880F7288>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488102E88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488101F08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A488110F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488115048>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48811F508>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880F9088>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880E9F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488104308>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488104DC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880E4908>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488D1A548>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488D27EC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A488D2D2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488D36D88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488D41EC8>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A488D437C8>, <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x000002A488D4EE08>, <tensorflow.python.keras.layers.core.Dense object at 0x000002A488D46408>]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "input_shape = x_train.shape[1:]\n",
    "print(\"input shape: \", input_shape)\n",
    "\n",
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras import backend as K\n",
    "\n",
    "# num_classes = 10\n",
    "# epochs = 20\n",
    "\n",
    "\n",
    "# def euclidean_distance(vects):\n",
    "#     x, y = vects\n",
    "#     sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "#     return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "# def eucl_dist_output_shape(shapes):\n",
    "#     shape1, shape2 = shapes\n",
    "#     return (shape1[0], 1)\n",
    "\n",
    "\n",
    "# def contrastive_loss(y_true, y_pred):\n",
    "#     '''Contrastive loss from Hadsell-et-al.'06\n",
    "#     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "#     '''\n",
    "#     margin = 1\n",
    "#     square_pred = K.square(y_pred)\n",
    "#     margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "#     return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "# def create_pairs(x, digit_indices):\n",
    "#     '''Positive and negative pair creation.\n",
    "#     Alternates between positive and negative pairs.\n",
    "#     '''\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "#     n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "#     for d in range(num_classes):\n",
    "#         for i in range(n):\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             inc = random.randrange(1, num_classes)\n",
    "#             dn = (d + inc) % num_classes\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             labels += [1, 0]\n",
    "#     return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "# def compute_accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     pred = y_pred.ravel() < 0.5\n",
    "#     return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# input_shape = x_train.shape[1:]\n",
    "\n",
    "# # create training+test positive and negative pairs\n",
    "# digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "# tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "# digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "# te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# # network definition\n",
    "# base_network = create_base_network(input_shape)\n",
    "\n",
    "# input_a = Input(shape=input_shape)\n",
    "# input_b = Input(shape=input_shape)\n",
    "\n",
    "# # because we re-use the same instance `base_network`,\n",
    "# # the weights of the network\n",
    "# # will be shared across the two branches\n",
    "# processed_a = base_network(input_a)\n",
    "# processed_b = base_network(input_b)\n",
    "\n",
    "# distance = Lambda(euclidean_distance,\n",
    "#                   output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# model = Model([input_a, input_b], distance)\n",
    "\n",
    "# # train\n",
    "# rms = RMSprop()\n",
    "# model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "# model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "#           batch_size=128,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# # compute final accuracy on training and test sets\n",
    "# y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "# tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "# y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "# te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "# print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "# print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Module use of python35.dll conflicts with this version of Python.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-6e7bb19bc708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Libs\\caffe\\python\\caffe\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Libs\\caffe\\python\\caffe\\pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Module use of python35.dll conflicts with this version of Python."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
