{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress Tensorflow verbose prints\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from form_train_data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "data_path = Path.cwd() / 'data'\n",
    "train_dataset_path = data_path / 'CASIA-WebFace-112x96'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "Loading test data\n"
     ]
    }
   ],
   "source": [
    "print(\"CASIA pairs for training\")\n",
    "print(\"LFW pairs for testing\")\n",
    "casia_pairs, lfw_pairs = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle casia_list\n"
     ]
    }
   ],
   "source": [
    "print(\"shuffle casia list\")\n",
    "np.random.shuffle(casia_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to pandas dataframe\n",
      "test dataframe\n",
      "                                                  fileL  \\\n",
      "0                    Abel_Pacheco\\Abel_Pacheco_0001.jpg   \n",
      "1                Akhmed_Zakayev\\Akhmed_Zakayev_0001.jpg   \n",
      "2                Akhmed_Zakayev\\Akhmed_Zakayev_0002.jpg   \n",
      "3                  Amber_Tamblyn\\Amber_Tamblyn_0001.jpg   \n",
      "4                Angela_Bassett\\Angela_Bassett_0001.jpg   \n",
      "...                                                 ...   \n",
      "5597                     Scott_Wolf\\Scott_Wolf_0002.jpg   \n",
      "5598  Sergei_Alexandrovitch_Ordzhonikidze\\Sergei_Ale...   \n",
      "5599                     Shane_Loux\\Shane_Loux_0001.jpg   \n",
      "5600                 Shawn_Marion\\Shawn_Marion_0001.jpg   \n",
      "5601     Slobodan_Milosevic\\Slobodan_Milosevic_0002.jpg   \n",
      "\n",
      "                                       fileR  flag  \n",
      "0         Abel_Pacheco\\Abel_Pacheco_0004.jpg     1  \n",
      "1     Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "2     Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "3       Amber_Tamblyn\\Amber_Tamblyn_0002.jpg     1  \n",
      "4     Angela_Bassett\\Angela_Bassett_0005.jpg     1  \n",
      "...                                      ...   ...  \n",
      "5597    Troy_Polamalu\\Troy_Polamalu_0001.jpg     0  \n",
      "5598      Yolanda_King\\Yolanda_King_0001.jpg     0  \n",
      "5599      Val_Ackerman\\Val_Ackerman_0001.jpg     0  \n",
      "5600    Shirley_Jones\\Shirley_Jones_0001.jpg     0  \n",
      "5601                  Sok_An\\Sok_An_0001.jpg     0  \n",
      "\n",
      "[5602 rows x 3 columns]\n",
      "\n",
      "train dataframe\n",
      "                    fileL            fileR  flag\n",
      "0         0633604\\137.jpg  0633604\\187.jpg     1\n",
      "1         0579953\\021.jpg  1952233\\031.jpg     0\n",
      "2         1466205\\009.jpg  1466205\\011.jpg     1\n",
      "3         0005447\\099.jpg  0005447\\144.jpg     1\n",
      "4         0385293\\105.jpg  0385293\\143.jpg     1\n",
      "...                   ...              ...   ...\n",
      "47006103  0424060\\017.jpg  0424060\\132.jpg     1\n",
      "47006104  1936361\\004.jpg  1936361\\008.jpg     1\n",
      "47006105  1842439\\073.jpg  1842439\\148.jpg     1\n",
      "47006106  0570860\\003.jpg  0095746\\037.jpg     0\n",
      "47006107  0736622\\130.jpg  0773056\\041.jpg     0\n",
      "\n",
      "[47006108 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"convert to pandas dataframe\")\n",
    "lfw_list = lfw_pairs.tolist()\n",
    "casia_list = casia_pairs.tolist()\n",
    "test_dataframe = pd.DataFrame(lfw_list)\n",
    "train_dataframe = pd.DataFrame(casia_list) # takes long time\n",
    "\n",
    "print(\"test dataframe\")\n",
    "print(test_dataframe)\n",
    "print()\n",
    "print(\"train dataframe\")\n",
    "print(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe['flag'] = train_dataframe['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myphi(x,m):\n",
    "#     x = x * m\n",
    "#     return 1 - x**2/math.factorial(2) + x**4/math.factorial(4) - x**6/math.factorial(6) + x**8/math.factorial(8) - x**9/math.factorial(9)\n",
    "\n",
    "# class MarginInnerProductLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, in_features, out_features, m=4, phiflag=True):\n",
    "#         super(MarginInnerProductLayer, self).__init__()\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.phiflag = phiflag\n",
    "#         self.m = m\n",
    "#         self.mlambda = [\n",
    "#             lambda x: x**0,\n",
    "#             lambda x: x**1,\n",
    "#             lambda x: 2*x**2-1,\n",
    "#             lambda x: 4*x**3-3*x,\n",
    "#             lambda x: 8*x**4-8*x**2+1,\n",
    "#             lambda x: 16*x**5-20*x**3+5*x\n",
    "#         ]\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         #Create a trainable weight variable for this layer.\n",
    "#         self.kernel = self.add_weight(name='fc6', shape=(self.in_features, self.out_features), initializer='uniform', trainable=True)\n",
    "#         super(MarginInnerProductLayer, self).build(input_shape)\n",
    "\n",
    "#     def call(self, x):    \n",
    "#         x1 = x\n",
    "#         w1 = self.kernel\n",
    "\n",
    "#         x2 = K.pow(x1,2)\n",
    "#         x2 = K.sum(x2,1)\n",
    "#         x2 = K.pow(x2,0.5)\n",
    "\n",
    "#         w2 = K.pow(w1,2)\n",
    "#         w2 = K.sum(w2,0)\n",
    "#         w2 = K.pow(w2,0.5)\n",
    "\n",
    "#         x1 = K.variable(value=x1)\n",
    "#         w1 = K.variable(value=w1)\n",
    "\n",
    "#         cos_theta = K.dot(x1,w1)\n",
    "#         cos_theta = cos_theta / K.reshape(x2,(-1,1)) / K.reshape(w2,(1,-1))\n",
    "#         cos_theta = K.clip(cos_theta, -1, 1)\n",
    "\n",
    "#         if self.phiflag:\n",
    "            \n",
    "#             cos_m_theta = self.mlambda[self.m](cos_theta)\n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             k = math.floor(self.m*theta/3.14159265)\n",
    "#             n_one = k*0.0 - 1\n",
    "#             phi_theta = (n_one**k) * cos_m_theta - 2*k\n",
    "\n",
    "#         else:\n",
    "            \n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             phi_theta = myphi(theta,self.m)\n",
    "#             phi_theta = K.clip(phi_theta, -1*self.m, 1)\n",
    "\n",
    "#         cos_theta = cos_theta * K.reshape(x2,(-1,1))\n",
    "#         phi_theta = phi_theta * K.reshape(x2,(-1,1))\n",
    "#         output = (cos_theta,phi_theta)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.out_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Add, Activation, PReLU, Dense, Input, ZeroPadding2D, Lambda, GlobalAveragePooling2D, Dot \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CosineSimilarity\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def conv_3_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=2, padding='valid', kernel_initializer='glorot_uniform')(x)\n",
    "    r1 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r1)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r2 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r2)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r3 = PReLU()(x)\n",
    "\n",
    "    x = Add()([r1, r3])\n",
    "    return x \n",
    "\n",
    "def conv_2_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Add()([input, x])\n",
    "    return x\n",
    "\n",
    "def sphereface20(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = conv_3_block(input, 64)\n",
    "    x = conv_3_block(x, 128)\n",
    "    x = conv_2_block(x, 128)\n",
    "    x = conv_3_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_3_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "# https://keras.io/examples/mnist_siamese/\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# https://stackoverflow.com/questions/51003027/computing-cosine-similarity-between-two-tensors-in-keras\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "\n",
    "# network definition\n",
    "input_shape = (112, 96, 3)\n",
    "base_network = sphereface20(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_path = str(Path.cwd().parent / 'models' / 'sphereface_20_keras' / 'sphereface_20.json')\n",
    "model_json = base_network.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 112, 96, 3)] input_26\n",
      "(None, 114, 98, 3) zero_padding2d_260\n",
      "(None, 56, 48, 64) conv2d_260\n",
      "(None, 56, 48, 64) p_re_lu_260\n",
      "(None, 58, 50, 64) zero_padding2d_261\n",
      "(None, 56, 48, 64) conv2d_261\n",
      "(None, 56, 48, 64) p_re_lu_261\n",
      "(None, 58, 50, 64) zero_padding2d_262\n",
      "(None, 56, 48, 64) conv2d_262\n",
      "(None, 56, 48, 64) p_re_lu_262\n",
      "(None, 56, 48, 64) add_104\n",
      "(None, 58, 50, 64) zero_padding2d_263\n",
      "(None, 28, 24, 128) conv2d_263\n",
      "(None, 28, 24, 128) p_re_lu_263\n",
      "(None, 30, 26, 128) zero_padding2d_264\n",
      "(None, 28, 24, 128) conv2d_264\n",
      "(None, 28, 24, 128) p_re_lu_264\n",
      "(None, 30, 26, 128) zero_padding2d_265\n",
      "(None, 28, 24, 128) conv2d_265\n",
      "(None, 28, 24, 128) p_re_lu_265\n",
      "(None, 28, 24, 128) add_105\n",
      "(None, 30, 26, 128) zero_padding2d_266\n",
      "(None, 28, 24, 128) conv2d_266\n",
      "(None, 28, 24, 128) p_re_lu_266\n",
      "(None, 30, 26, 128) zero_padding2d_267\n",
      "(None, 28, 24, 128) conv2d_267\n",
      "(None, 28, 24, 128) p_re_lu_267\n",
      "(None, 28, 24, 128) add_106\n",
      "(None, 30, 26, 128) zero_padding2d_268\n",
      "(None, 14, 12, 256) conv2d_268\n",
      "(None, 14, 12, 256) p_re_lu_268\n",
      "(None, 16, 14, 256) zero_padding2d_269\n",
      "(None, 14, 12, 256) conv2d_269\n",
      "(None, 14, 12, 256) p_re_lu_269\n",
      "(None, 16, 14, 256) zero_padding2d_270\n",
      "(None, 14, 12, 256) conv2d_270\n",
      "(None, 14, 12, 256) p_re_lu_270\n",
      "(None, 14, 12, 256) add_107\n",
      "(None, 16, 14, 256) zero_padding2d_271\n",
      "(None, 14, 12, 256) conv2d_271\n",
      "(None, 14, 12, 256) p_re_lu_271\n",
      "(None, 16, 14, 256) zero_padding2d_272\n",
      "(None, 14, 12, 256) conv2d_272\n",
      "(None, 14, 12, 256) p_re_lu_272\n",
      "(None, 14, 12, 256) add_108\n",
      "(None, 16, 14, 256) zero_padding2d_273\n",
      "(None, 14, 12, 256) conv2d_273\n",
      "(None, 14, 12, 256) p_re_lu_273\n",
      "(None, 16, 14, 256) zero_padding2d_274\n",
      "(None, 14, 12, 256) conv2d_274\n",
      "(None, 14, 12, 256) p_re_lu_274\n",
      "(None, 14, 12, 256) add_109\n",
      "(None, 16, 14, 256) zero_padding2d_275\n",
      "(None, 14, 12, 256) conv2d_275\n",
      "(None, 14, 12, 256) p_re_lu_275\n",
      "(None, 16, 14, 256) zero_padding2d_276\n",
      "(None, 14, 12, 256) conv2d_276\n",
      "(None, 14, 12, 256) p_re_lu_276\n",
      "(None, 14, 12, 256) add_110\n",
      "(None, 16, 14, 256) zero_padding2d_277\n",
      "(None, 7, 6, 512) conv2d_277\n",
      "(None, 7, 6, 512) p_re_lu_277\n",
      "(None, 9, 8, 512) zero_padding2d_278\n",
      "(None, 7, 6, 512) conv2d_278\n",
      "(None, 7, 6, 512) p_re_lu_278\n",
      "(None, 9, 8, 512) zero_padding2d_279\n",
      "(None, 7, 6, 512) conv2d_279\n",
      "(None, 7, 6, 512) p_re_lu_279\n",
      "(None, 7, 6, 512) add_111\n",
      "(None, 512) global_average_pooling2d_2\n",
      "(None, 512) dense_10\n",
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000002A48B32E988>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A614576108>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CC6308>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CC8748>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CC8588>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CD0748>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CD5908>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CD8908>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CE3048>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CE4D88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4F3CE7048>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CF0DC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4F3CFC488>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4F3CFCD48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4F3CFF848>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3B3A88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3B9408>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3C1088>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3C7B48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3CE908>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A3D0708>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3DCD88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3DE388>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3E0EC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3E0D48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A3EA988>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A3F1A88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A3F3388>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A3FB2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A400CC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A407D48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A407CC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A40E1C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A413888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A419E48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A41EC48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A426D48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A426B88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A42FC88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A436848>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A438D88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A43B348>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A43FE08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A448F48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A449888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A454D08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A458F48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A45BD88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A45F1C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A464C48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A46BA08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A46F808>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A47BB48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A47D4C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A482A88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A47FF88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A489A88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A48F848>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A491648>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A499348>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A49CE08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4A3E48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A4A3E08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A4AF5C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4B4A08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A50A4BCB48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A50A4B6788>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A50A4C5F08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A50A4C5D08>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x000002A50A4CD648>, <tensorflow.python.keras.layers.core.Dense object at 0x000002A50A4D6048>]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"sparse\"\n",
    "    generator = ImageDataGenerator(preprocessing_function=preprocess_image,\n",
    "                                   validation_split=0.01)\n",
    "    \n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    \n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net: \"code/sphereface_model.prototxt\"\n",
    "# #test_iter: 100 \n",
    "# #test_interval: 2000\n",
    "\n",
    "# base_lr: 0.1\n",
    "# lr_policy: \"multistep\"\n",
    "# gamma: 0.1\n",
    "\n",
    "# stepvalue: 16000\n",
    "# stepvalue: 24000\n",
    "# stepvalue: 28000\n",
    "# max_iter: 28000\n",
    "\n",
    "# display: 100\n",
    "# momentum: 0.9\n",
    "# weight_decay: 0.0005\n",
    "# #snapshot: 1000\n",
    "# snapshot_prefix: \"result/sphereface_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "# optimizer_ = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "optimizer_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "# loss_ = custom_loss\n",
    "# loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer_, metrics=[accuracy])\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.05 GiB for an array with shape (3, 47006108) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-dafa4398c9c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://github.com/keras-team/keras/issues/10855\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[0;32m    770\u001b[0m     \u001b[1;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m     \u001b[1;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 772\u001b[1;33m     \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    773\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    828\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m     \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    831\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpeek\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeek\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-110-994ff90ef5fb>\u001b[0m in \u001b[0;36mtrain_generator\u001b[1;34m(train_dataframe, batch_size_)\u001b[0m\n\u001b[0;32m     24\u001b[0m                              \u001b[0mclass_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_mode_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                              \u001b[0mcolor_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                              target_size=(112, 96))\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     train_generator_X2 = generator.flow_from_dataframe(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[1;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             \u001b[0minterpolation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m             \u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_filenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    684\u001b[0m         )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, dtype, validate_filenames)\u001b[0m\n\u001b[0;32m    122\u001b[0m                                                             \u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m                                                             interpolation)\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5809\u001b[0m         \"\"\"\n\u001b[1;32m-> 5810\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5811\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"copy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m         \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m                 \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 695\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    696\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.05 GiB for an array with shape (3, 47006108) and data type object"
     ]
    }
   ],
   "source": [
    "batch_size_ = 64\n",
    "epochs_ = 2\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "hist = model.fit_generator(train_generator(train_dataframe, batch_size_), epochs=epochs_, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casia_pairs_short = []\n",
    "lfw_pairs_short = []\n",
    "\n",
    "i_0 = 0 # number of pairs with 'flag' == 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(casia_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "\n",
    "i_0 = 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(lfw_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "        \n",
    "# convert to pandas dataframe\n",
    "test_dataframe_short = pd.DataFrame(lfw_list_short)\n",
    "train_dataframe_short = pd.DataFrame(casia_list_short) # takes long time\n",
    "\n",
    "print(\"short test dataframe\")\n",
    "print(test_dataframe_short)\n",
    "print()\n",
    "print(\"short train dataframe\")\n",
    "print(train_dataframe_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe_short['flag'] = train_dataframe_short['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fileL': '0000045\\\\001.jpg', 'fileR': '0000045\\\\002.jpg', 'flag': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lfw_pairs[0]\n",
    "casia_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator(train_dataframe, batch_size):\n",
    "    generator = ImageDataGenerator(\n",
    "                             fill_mode=\"nearest\",\n",
    "                             cval=0.0,\n",
    "                             horizontal_flip=False,\n",
    "                             vertical_flip=False,\n",
    "                             rescale=None,\n",
    "                             preprocessing_function=preprocess_image,\n",
    "                             data_format=None,\n",
    "                             validation_split=0.001,\n",
    "                             dtype=None)\n",
    "    \n",
    "    valid_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))  \n",
    "\n",
    "    valid_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = valid_generator_X1.next()\n",
    "        X2i = valid_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n",
    "\n",
    "\n",
    "\n",
    "def test_generator(test_dataframe, batch_size):\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                             preprocessing_function=preprocess_image) \n",
    "    test_generator_X1 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(data_path.parent.parent / 'test' / 'data' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "\n",
    "    test_generator_X2 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(data_path.parent.parent / 'test' / 'data' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "    while True:\n",
    "        X1i = test_generator_X1.next()\n",
    "        X2i = test_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2data(dt, dataset_path):\n",
    "    fileL_paths = list(map(lambda x: str(dataset_path / x), dt['fileL'].to_list()))\n",
    "    fileR_paths = list(map(lambda x: str(dataset_path / x), dt['fileR'].to_list()))\n",
    "    Y = list(map(lambda x: int(x), dt['flag'].to_list()))\n",
    "    \n",
    "    X1 = []\n",
    "    for path in fileL_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X1.append(image)\n",
    "    \n",
    "    X2 = []   \n",
    "    for path in fileR_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X2.append(image)\n",
    "    \n",
    "    return [X1, X2], Y\n",
    "\n",
    "X, Y = dataframe2data(train_dataframe, train_dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 96, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27e6b65d908>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X[0][0].shape)\n",
    "# print(X[0][0])\n",
    "plt.imshow(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\Face_Identification\\sphereface_keras\\train\\data\\CASIA-WebFace-112x96\\0000045\\001.jpg\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_path / casia_pairs[0]['fileL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|                                              | 0/1200 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|                              | 124/1200 [00:00<00:00, 1234.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|                           | 248/1200 [00:00<00:00, 1232.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|                       | 371/1200 [00:00<00:00, 1229.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|                    | 495/1200 [00:00<00:00, 1230.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|                | 619/1200 [00:00<00:00, 1232.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|              | 722/1200 [00:04<00:05, 90.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|            | 795/1200 [00:08<00:09, 41.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|          | 847/1200 [00:10<00:11, 31.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|         | 884/1200 [00:12<00:12, 25.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|        | 911/1200 [00:14<00:12, 22.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|        | 930/1200 [00:15<00:12, 21.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|       | 944/1200 [00:15<00:12, 20.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|       | 955/1200 [00:16<00:12, 20.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|       | 963/1200 [00:16<00:11, 20.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|       | 970/1200 [00:17<00:11, 20.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|      | 975/1200 [00:17<00:11, 20.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|      | 979/1200 [00:17<00:09, 22.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|      | 983/1200 [00:17<00:09, 22.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|      | 987/1200 [00:18<00:09, 22.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|      | 990/1200 [00:18<00:08, 24.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|      | 993/1200 [00:18<00:08, 23.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|      | 996/1200 [00:18<00:10, 19.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|      | 999/1200 [00:18<00:10, 18.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|     | 1002/1200 [00:18<00:10, 18.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|     | 1005/1200 [00:18<00:10, 18.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|     | 1008/1200 [00:19<00:10, 19.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|     | 1011/1200 [00:19<00:10, 18.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|     | 1013/1200 [00:19<00:11, 16.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|     | 1016/1200 [00:19<00:10, 17.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|     | 1019/1200 [00:19<00:10, 17.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|     | 1022/1200 [00:19<00:09, 18.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|     | 1025/1200 [00:20<00:08, 20.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|     | 1028/1200 [00:20<00:09, 18.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|     | 1030/1200 [00:20<00:09, 18.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|    | 1033/1200 [00:20<00:08, 18.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|    | 1036/1200 [00:20<00:07, 20.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|    | 1039/1200 [00:20<00:07, 21.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|    | 1042/1200 [00:20<00:07, 20.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|    | 1045/1200 [00:21<00:07, 20.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|    | 1048/1200 [00:21<00:07, 21.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|    | 1051/1200 [00:21<00:07, 21.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|    | 1054/1200 [00:21<00:06, 21.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|    | 1057/1200 [00:21<00:07, 19.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|    | 1060/1200 [00:21<00:07, 17.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|    | 1062/1200 [00:21<00:08, 15.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|    | 1064/1200 [00:22<00:08, 16.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|    | 1066/1200 [00:22<00:07, 17.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|   | 1069/1200 [00:22<00:07, 17.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|   | 1071/1200 [00:22<00:07, 17.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|   | 1073/1200 [00:22<00:07, 17.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|   | 1075/1200 [00:22<00:07, 15.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|   | 1078/1200 [00:22<00:07, 16.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|   | 1081/1200 [00:23<00:06, 17.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|   | 1083/1200 [00:23<00:07, 16.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|   | 1086/1200 [00:23<00:06, 17.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|   | 1088/1200 [00:23<00:06, 16.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|   | 1090/1200 [00:23<00:06, 16.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|   | 1092/1200 [00:23<00:06, 16.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|   | 1095/1200 [00:23<00:05, 17.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|   | 1097/1200 [00:24<00:06, 16.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|   | 1100/1200 [00:24<00:05, 18.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|  | 1103/1200 [00:24<00:04, 20.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|  | 1106/1200 [00:24<00:04, 19.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|  | 1109/1200 [00:24<00:04, 20.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|  | 1112/1200 [00:24<00:04, 20.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|  | 1115/1200 [00:24<00:04, 17.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|  | 1118/1200 [00:25<00:04, 18.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|  | 1120/1200 [00:25<00:04, 18.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1123/1200 [00:25<00:03, 19.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1125/1200 [00:25<00:04, 18.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1127/1200 [00:25<00:04, 17.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1129/1200 [00:25<00:04, 16.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1132/1200 [00:25<00:03, 18.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|  | 1134/1200 [00:25<00:03, 18.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%| | 1136/1200 [00:26<00:03, 18.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%| | 1139/1200 [00:26<00:02, 20.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%| | 1142/1200 [00:26<00:02, 20.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%| | 1145/1200 [00:26<00:02, 21.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%| | 1148/1200 [00:26<00:02, 22.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%| | 1151/1200 [00:26<00:02, 18.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%| | 1154/1200 [00:26<00:02, 18.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%| | 1157/1200 [00:27<00:02, 19.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%| | 1160/1200 [00:27<00:02, 19.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%| | 1163/1200 [00:27<00:01, 19.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%| | 1166/1200 [00:27<00:01, 17.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%| | 1169/1200 [00:27<00:01, 18.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|| 1171/1200 [00:27<00:01, 16.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|| 1174/1200 [00:27<00:01, 18.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|| 1177/1200 [00:28<00:01, 19.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|| 1180/1200 [00:28<00:00, 21.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|| 1183/1200 [00:28<00:00, 21.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|| 1186/1200 [00:28<00:00, 21.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|| 1189/1200 [00:28<00:00, 20.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|| 1192/1200 [00:28<00:00, 22.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 1195/1200 [00:28<00:00, 21.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|| 1200/1200 [00:29<00:00, 41.11it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "Y = []\n",
    "for pair in tqdm(casia_pairs_short):\n",
    "    imageL = cv2.imread(str(train_dataset_path / pair['fileL']))\n",
    "    imageL = preprocess_image(imageL)\n",
    "    imageR = cv2.imread(str(train_dataset_path / pair['fileR']))\n",
    "    imageR = preprocess_image(imageR)\n",
    "    X1.append(imageL)\n",
    "    X2.append(imageR)\n",
    "    Y.append(pair['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 112, 96, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = np.asarray(X1)\n",
    "X2 = np.asarray(X2)\n",
    "Y = np.asarray(Y)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "batch_size_ = 64\n",
    "epochs_ = 6\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "rms_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])\n",
    "# model.compile(loss=contrastive_loss, optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "def generator_two_img(X1, X2, y, batch_size):\n",
    "    generator = ImageDataGenerator()\n",
    "    \n",
    "    genX1 = generator.flow(X1, y,  batch_size=batch_size, seed=1)\n",
    "    genX2 = generator.flow(X2, y, batch_size=batch_size, seed=1)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "18/18 [==============================] - 125s 7s/step - loss: 0.2686 - accuracy: 0.6094\n",
      "Epoch 2/2\n",
      "18/18 [==============================] - 122s 7s/step - loss: 0.3000 - accuracy: 0.5770\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(generator_two_img(X1, X2, Y, batch_size_),\n",
    "                           steps_per_epoch=len(X1)//batch_size_, \n",
    "                           epochs=epochs_,\n",
    "                           callbacks = None, \n",
    "                           shuffle=True)\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "# hist = model.fit(X, Y, epochs=epochs_, batch_size=batch_size_)\n",
    "# hist = model.fit(x=X, \n",
    "#                  y=Y, \n",
    "#                  batch_size=batch_size_, \n",
    "#                  epochs=epochs_, \n",
    "#                  verbose=1, \n",
    "#                  callbacks=None,\n",
    "#                  validation_split=0.01, \n",
    "#                  validation_data=None, \n",
    "#                  shuffle=True, \n",
    "#                  class_weight=None,\n",
    "#                  sample_weight=None, \n",
    "#                  initial_epoch=0, \n",
    "#                  steps_per_epoch=None,\n",
    "#                  validation_steps=None, \n",
    "#                  validation_batch_size=None, \n",
    "#                  validation_freq=1,\n",
    "#                  max_queue_size=10, \n",
    "#                  workers=1, \n",
    "#                  use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 96, 3), (112, 96, 3), 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1[0].shape, X2[0].shape, Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 96, 3) (1, 112, 96, 3)\n"
     ]
    }
   ],
   "source": [
    "X1_test = np.expand_dims(X1[0], 0)\n",
    "X2_test = np.expand_dims(X2[0], 0)\n",
    "print(X1_test.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7, 6, 512)\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "prediction = base_network.predict(X1_test)\n",
    "print(prediction.shape)\n",
    "# print(prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 112, 96, 3)] input_12\n",
      "(None, 114, 98, 3) zero_padding2d_100\n",
      "(None, 56, 48, 64) conv2d_100\n",
      "(None, 56, 48, 64) p_re_lu_100\n",
      "(None, 58, 50, 64) zero_padding2d_101\n",
      "(None, 56, 48, 64) conv2d_101\n",
      "(None, 56, 48, 64) p_re_lu_101\n",
      "(None, 58, 50, 64) zero_padding2d_102\n",
      "(None, 56, 48, 64) conv2d_102\n",
      "(None, 56, 48, 64) p_re_lu_102\n",
      "(None, 56, 48, 64) add_40\n",
      "(None, 58, 50, 64) zero_padding2d_103\n",
      "(None, 28, 24, 128) conv2d_103\n",
      "(None, 28, 24, 128) p_re_lu_103\n",
      "(None, 30, 26, 128) zero_padding2d_104\n",
      "(None, 28, 24, 128) conv2d_104\n",
      "(None, 28, 24, 128) p_re_lu_104\n",
      "(None, 30, 26, 128) zero_padding2d_105\n",
      "(None, 28, 24, 128) conv2d_105\n",
      "(None, 28, 24, 128) p_re_lu_105\n",
      "(None, 28, 24, 128) add_41\n",
      "(None, 30, 26, 128) zero_padding2d_106\n",
      "(None, 28, 24, 128) conv2d_106\n",
      "(None, 28, 24, 128) p_re_lu_106\n",
      "(None, 30, 26, 128) zero_padding2d_107\n",
      "(None, 28, 24, 128) conv2d_107\n",
      "(None, 28, 24, 128) p_re_lu_107\n",
      "(None, 28, 24, 128) add_42\n",
      "(None, 30, 26, 128) zero_padding2d_108\n",
      "(None, 14, 12, 256) conv2d_108\n",
      "(None, 14, 12, 256) p_re_lu_108\n",
      "(None, 16, 14, 256) zero_padding2d_109\n",
      "(None, 14, 12, 256) conv2d_109\n",
      "(None, 14, 12, 256) p_re_lu_109\n",
      "(None, 16, 14, 256) zero_padding2d_110\n",
      "(None, 14, 12, 256) conv2d_110\n",
      "(None, 14, 12, 256) p_re_lu_110\n",
      "(None, 14, 12, 256) add_43\n",
      "(None, 16, 14, 256) zero_padding2d_111\n",
      "(None, 14, 12, 256) conv2d_111\n",
      "(None, 14, 12, 256) p_re_lu_111\n",
      "(None, 16, 14, 256) zero_padding2d_112\n",
      "(None, 14, 12, 256) conv2d_112\n",
      "(None, 14, 12, 256) p_re_lu_112\n",
      "(None, 14, 12, 256) add_44\n",
      "(None, 16, 14, 256) zero_padding2d_113\n",
      "(None, 14, 12, 256) conv2d_113\n",
      "(None, 14, 12, 256) p_re_lu_113\n",
      "(None, 16, 14, 256) zero_padding2d_114\n",
      "(None, 14, 12, 256) conv2d_114\n",
      "(None, 14, 12, 256) p_re_lu_114\n",
      "(None, 14, 12, 256) add_45\n",
      "(None, 16, 14, 256) zero_padding2d_115\n",
      "(None, 14, 12, 256) conv2d_115\n",
      "(None, 14, 12, 256) p_re_lu_115\n",
      "(None, 16, 14, 256) zero_padding2d_116\n",
      "(None, 14, 12, 256) conv2d_116\n",
      "(None, 14, 12, 256) p_re_lu_116\n",
      "(None, 14, 12, 256) add_46\n",
      "(None, 16, 14, 256) zero_padding2d_117\n",
      "(None, 7, 6, 512) conv2d_117\n",
      "(None, 7, 6, 512) p_re_lu_117\n",
      "(None, 9, 8, 512) zero_padding2d_118\n",
      "(None, 7, 6, 512) conv2d_118\n",
      "(None, 7, 6, 512) p_re_lu_118\n",
      "(None, 9, 8, 512) zero_padding2d_119\n",
      "(None, 7, 6, 512) conv2d_119\n",
      "(None, 7, 6, 512) p_re_lu_119\n",
      "(None, 7, 6, 512) add_47\n",
      "(None, 7, 6, 512) average_pooling2d_1\n",
      "(None, 7, 6, 512) dense_3\n",
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x000002A48E552D88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5356FE108>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488E676C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48E6EFF88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A48E6EFDC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A48E6E40C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48E70AE08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A53572B208>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535727CC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A535700A88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A535723888>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A535709BC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A53577D388>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A53577CD08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A53577A148>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535787B88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A535792F08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A535797E88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357A3608>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357AA488>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A5357AE208>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357ABD08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357A2788>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357A2B48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357937C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A535773148>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357BEC48>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A5357C20C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357D1BC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357DF488>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357DFBC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357E5B88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357E0F88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357C5F48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A5357C5F08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A5357C4A08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A5357D4B08>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880A16C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880AE2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880B8F08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880BDE48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880C6F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880CB748>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880D8588>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880D9488>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880AD0C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880AAD88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880C4C88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880D7EC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A4880E0908>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A4880EAD88>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880EC508>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880F7288>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488102E88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488101F08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A488110F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488115048>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A48811F508>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A4880F9088>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880E9F48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488104308>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488104DC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A4880E4908>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488D1A548>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488D27EC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x000002A488D2D2C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x000002A488D36D88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x000002A488D41EC8>, <tensorflow.python.keras.layers.merge.Add object at 0x000002A488D437C8>, <tensorflow.python.keras.layers.pooling.AveragePooling2D object at 0x000002A488D4EE08>, <tensorflow.python.keras.layers.core.Dense object at 0x000002A488D46408>]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape:  (28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "input_shape = x_train.shape[1:]\n",
    "print(\"input shape: \", input_shape)\n",
    "\n",
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras import backend as K\n",
    "\n",
    "# num_classes = 10\n",
    "# epochs = 20\n",
    "\n",
    "\n",
    "# def euclidean_distance(vects):\n",
    "#     x, y = vects\n",
    "#     sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "#     return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "# def eucl_dist_output_shape(shapes):\n",
    "#     shape1, shape2 = shapes\n",
    "#     return (shape1[0], 1)\n",
    "\n",
    "\n",
    "# def contrastive_loss(y_true, y_pred):\n",
    "#     '''Contrastive loss from Hadsell-et-al.'06\n",
    "#     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "#     '''\n",
    "#     margin = 1\n",
    "#     square_pred = K.square(y_pred)\n",
    "#     margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "#     return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "# def create_pairs(x, digit_indices):\n",
    "#     '''Positive and negative pair creation.\n",
    "#     Alternates between positive and negative pairs.\n",
    "#     '''\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "#     n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "#     for d in range(num_classes):\n",
    "#         for i in range(n):\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             inc = random.randrange(1, num_classes)\n",
    "#             dn = (d + inc) % num_classes\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             labels += [1, 0]\n",
    "#     return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "# def compute_accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     pred = y_pred.ravel() < 0.5\n",
    "#     return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# input_shape = x_train.shape[1:]\n",
    "\n",
    "# # create training+test positive and negative pairs\n",
    "# digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "# tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "# digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "# te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# # network definition\n",
    "# base_network = create_base_network(input_shape)\n",
    "\n",
    "# input_a = Input(shape=input_shape)\n",
    "# input_b = Input(shape=input_shape)\n",
    "\n",
    "# # because we re-use the same instance `base_network`,\n",
    "# # the weights of the network\n",
    "# # will be shared across the two branches\n",
    "# processed_a = base_network(input_a)\n",
    "# processed_b = base_network(input_b)\n",
    "\n",
    "# distance = Lambda(euclidean_distance,\n",
    "#                   output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# model = Model([input_a, input_b], distance)\n",
    "\n",
    "# # train\n",
    "# rms = RMSprop()\n",
    "# model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "# model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "#           batch_size=128,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# # compute final accuracy on training and test sets\n",
    "# y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "# tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "# y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "# te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "# print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "# print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Module use of python35.dll conflicts with this version of Python.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-6e7bb19bc708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Libs\\caffe\\python\\caffe\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpycaffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minit_log\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_cpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_mode_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_solver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer_type_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_solver_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_solver_rank\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_multiprocess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhas_nccl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaffe_pb2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Libs\\caffe\\python\\caffe\\pycaffe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_caffe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGDSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNesterovSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaGradSolver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mRMSPropSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdaDeltaSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdamSolver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNCCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcaffe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Module use of python35.dll conflicts with this version of Python."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
