{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress Tensorflow verbose prints\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from form_train_data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "datasets_path = Path.cwd().parent / 'datasets'\n",
    "train_dataset_path = datasets_path / 'CASIA-WebFace-112x96'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASIA pairs for training\n",
      "LFW pairs for testing\n",
      "Loading train data\n",
      "/home/paperspace/Projects/sphereface_keras/datasets/lfw_pairs.npz does not exist!\n",
      "You need to generate data first. Run generate_data(...) from form_train_data.\n"
     ]
    }
   ],
   "source": [
    "print(\"CASIA pairs for training\")\n",
    "print(\"LFW pairs for testing\")\n",
    "casia_pairs, lfw_pairs = load_data(datasets_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle casia list\n"
     ]
    }
   ],
   "source": [
    "print(\"shuffle casia list\")\n",
    "np.random.shuffle(casia_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert to pandas dataframe\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-15621473453b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"convert to pandas dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlfw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlfw_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcasia_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcasia_pairs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfw_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasia_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# takes long time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "del casia_list, lfw_list\n",
    "print(\"test dataframe\")\n",
    "print(test_dataframe)\n",
    "print()\n",
    "print(\"train dataframe\")\n",
    "print(train_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe['flag'] = train_dataframe['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myphi(x,m):\n",
    "#     x = x * m\n",
    "#     return 1 - x**2/math.factorial(2) + x**4/math.factorial(4) - x**6/math.factorial(6) + x**8/math.factorial(8) - x**9/math.factorial(9)\n",
    "\n",
    "# class MarginInnerProductLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, in_features, out_features, m=4, phiflag=True):\n",
    "#         super(MarginInnerProductLayer, self).__init__()\n",
    "#         self.in_features = in_features\n",
    "#         self.out_features = out_features\n",
    "#         self.phiflag = phiflag\n",
    "#         self.m = m\n",
    "#         self.mlambda = [\n",
    "#             lambda x: x**0,\n",
    "#             lambda x: x**1,\n",
    "#             lambda x: 2*x**2-1,\n",
    "#             lambda x: 4*x**3-3*x,\n",
    "#             lambda x: 8*x**4-8*x**2+1,\n",
    "#             lambda x: 16*x**5-20*x**3+5*x\n",
    "#         ]\n",
    "\n",
    "#     def build(self, input_shape):\n",
    "#         #Create a trainable weight variable for this layer.\n",
    "#         self.kernel = self.add_weight(name='fc6', shape=(self.in_features, self.out_features), initializer='uniform', trainable=True)\n",
    "#         super(MarginInnerProductLayer, self).build(input_shape)\n",
    "\n",
    "#     def call(self, x):    \n",
    "#         x1 = x\n",
    "#         w1 = self.kernel\n",
    "\n",
    "#         x2 = K.pow(x1,2)\n",
    "#         x2 = K.sum(x2,1)\n",
    "#         x2 = K.pow(x2,0.5)\n",
    "\n",
    "#         w2 = K.pow(w1,2)\n",
    "#         w2 = K.sum(w2,0)\n",
    "#         w2 = K.pow(w2,0.5)\n",
    "\n",
    "#         x1 = K.variable(value=x1)\n",
    "#         w1 = K.variable(value=w1)\n",
    "\n",
    "#         cos_theta = K.dot(x1,w1)\n",
    "#         cos_theta = cos_theta / K.reshape(x2,(-1,1)) / K.reshape(w2,(1,-1))\n",
    "#         cos_theta = K.clip(cos_theta, -1, 1)\n",
    "\n",
    "#         if self.phiflag:\n",
    "            \n",
    "#             cos_m_theta = self.mlambda[self.m](cos_theta)\n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             k = math.floor(self.m*theta/3.14159265)\n",
    "#             n_one = k*0.0 - 1\n",
    "#             phi_theta = (n_one**k) * cos_m_theta - 2*k\n",
    "\n",
    "#         else:\n",
    "            \n",
    "#             theta = tf.acos(cos_theta)\n",
    "#             phi_theta = myphi(theta,self.m)\n",
    "#             phi_theta = K.clip(phi_theta, -1*self.m, 1)\n",
    "\n",
    "#         cos_theta = cos_theta * K.reshape(x2,(-1,1))\n",
    "#         phi_theta = phi_theta * K.reshape(x2,(-1,1))\n",
    "#         output = (cos_theta,phi_theta)\n",
    "        \n",
    "#         return output\n",
    "\n",
    "#     def compute_output_shape(self, input_shape):\n",
    "#         return (input_shape[0], self.out_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Add, Activation, PReLU, Dense, Input, ZeroPadding2D, Lambda, GlobalAveragePooling2D, Dot \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CosineSimilarity\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def conv_3_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=2, padding='valid', kernel_initializer='glorot_uniform')(x)\n",
    "    r1 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r1)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r2 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r2)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r3 = PReLU()(x)\n",
    "\n",
    "    x = Add()([r1, r3])\n",
    "    return x \n",
    "\n",
    "def conv_2_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Add()([input, x])\n",
    "    return x\n",
    "\n",
    "def sphereface20(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = conv_3_block(input, 64)\n",
    "    x = conv_3_block(x, 128)\n",
    "    x = conv_2_block(x, 128)\n",
    "    x = conv_3_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_3_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "# https://keras.io/examples/mnist_siamese/\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# https://stackoverflow.com/questions/51003027/computing-cosine-similarity-between-two-tensors-in-keras\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "\n",
    "# network definition\n",
    "input_shape = (112, 96, 3)\n",
    "base_network = sphereface20(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_path = str(Path.cwd().parent / 'models' / 'sphereface_20_keras' / 'sphereface_20.json')\n",
    "model_json = base_network.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 112, 96, 3)] input_1\n",
      "(None, 114, 98, 3) zero_padding2d\n",
      "(None, 56, 48, 64) conv2d\n",
      "(None, 56, 48, 64) p_re_lu\n",
      "(None, 58, 50, 64) zero_padding2d_1\n",
      "(None, 56, 48, 64) conv2d_1\n",
      "(None, 56, 48, 64) p_re_lu_1\n",
      "(None, 58, 50, 64) zero_padding2d_2\n",
      "(None, 56, 48, 64) conv2d_2\n",
      "(None, 56, 48, 64) p_re_lu_2\n",
      "(None, 56, 48, 64) add\n",
      "(None, 58, 50, 64) zero_padding2d_3\n",
      "(None, 28, 24, 128) conv2d_3\n",
      "(None, 28, 24, 128) p_re_lu_3\n",
      "(None, 30, 26, 128) zero_padding2d_4\n",
      "(None, 28, 24, 128) conv2d_4\n",
      "(None, 28, 24, 128) p_re_lu_4\n",
      "(None, 30, 26, 128) zero_padding2d_5\n",
      "(None, 28, 24, 128) conv2d_5\n",
      "(None, 28, 24, 128) p_re_lu_5\n",
      "(None, 28, 24, 128) add_1\n",
      "(None, 30, 26, 128) zero_padding2d_6\n",
      "(None, 28, 24, 128) conv2d_6\n",
      "(None, 28, 24, 128) p_re_lu_6\n",
      "(None, 30, 26, 128) zero_padding2d_7\n",
      "(None, 28, 24, 128) conv2d_7\n",
      "(None, 28, 24, 128) p_re_lu_7\n",
      "(None, 28, 24, 128) add_2\n",
      "(None, 30, 26, 128) zero_padding2d_8\n",
      "(None, 14, 12, 256) conv2d_8\n",
      "(None, 14, 12, 256) p_re_lu_8\n",
      "(None, 16, 14, 256) zero_padding2d_9\n",
      "(None, 14, 12, 256) conv2d_9\n",
      "(None, 14, 12, 256) p_re_lu_9\n",
      "(None, 16, 14, 256) zero_padding2d_10\n",
      "(None, 14, 12, 256) conv2d_10\n",
      "(None, 14, 12, 256) p_re_lu_10\n",
      "(None, 14, 12, 256) add_3\n",
      "(None, 16, 14, 256) zero_padding2d_11\n",
      "(None, 14, 12, 256) conv2d_11\n",
      "(None, 14, 12, 256) p_re_lu_11\n",
      "(None, 16, 14, 256) zero_padding2d_12\n",
      "(None, 14, 12, 256) conv2d_12\n",
      "(None, 14, 12, 256) p_re_lu_12\n",
      "(None, 14, 12, 256) add_4\n",
      "(None, 16, 14, 256) zero_padding2d_13\n",
      "(None, 14, 12, 256) conv2d_13\n",
      "(None, 14, 12, 256) p_re_lu_13\n",
      "(None, 16, 14, 256) zero_padding2d_14\n",
      "(None, 14, 12, 256) conv2d_14\n",
      "(None, 14, 12, 256) p_re_lu_14\n",
      "(None, 14, 12, 256) add_5\n",
      "(None, 16, 14, 256) zero_padding2d_15\n",
      "(None, 14, 12, 256) conv2d_15\n",
      "(None, 14, 12, 256) p_re_lu_15\n",
      "(None, 16, 14, 256) zero_padding2d_16\n",
      "(None, 14, 12, 256) conv2d_16\n",
      "(None, 14, 12, 256) p_re_lu_16\n",
      "(None, 14, 12, 256) add_6\n",
      "(None, 16, 14, 256) zero_padding2d_17\n",
      "(None, 7, 6, 512) conv2d_17\n",
      "(None, 7, 6, 512) p_re_lu_17\n",
      "(None, 9, 8, 512) zero_padding2d_18\n",
      "(None, 7, 6, 512) conv2d_18\n",
      "(None, 7, 6, 512) p_re_lu_18\n",
      "(None, 9, 8, 512) zero_padding2d_19\n",
      "(None, 7, 6, 512) conv2d_19\n",
      "(None, 7, 6, 512) p_re_lu_19\n",
      "(None, 7, 6, 512) add_7\n",
      "(None, 512) global_average_pooling2d\n",
      "(None, 512) dense\n",
      "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x00000237DD6DAD48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD70BE48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD71DEC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD84BB08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD84BAC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD883208>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD88A748>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD88F688>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD896BC8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD89C348>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DD89CFC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD8A5CC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD8AE948>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD8AEB48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD8D8E88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD8D06C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD8E24C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD8E5108>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD8E98C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD8EFD88>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DD8F2708>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD8FED88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD8FF548>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DD9035C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DD905208>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DD90AD88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DE9F3C08>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DE9F3A48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DE9FEB88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA07208>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA05988>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA0A308>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA0FE48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA1A948>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA16C48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA215C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA26B08>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DEA29608>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA30348>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA38F08>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA3E908>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA3BDC8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA435C8>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA494C8>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DEA4A4C8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA55248>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA5AF48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA5DDC8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA5DD88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA66888>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA6E9C8>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DEA70488>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA770C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA7CE88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA7ED08>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA84F08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA89648>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEA8F948>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DEA92408>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEA9B048>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEA9FC48>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEAA7D48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEAA5F08>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEAAE648>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEAB4948>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x00000237DEAB75C8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x00000237DEABBA88>, <tensorflow.python.keras.layers.advanced_activations.PReLU object at 0x00000237DEAC9988>, <tensorflow.python.keras.layers.merge.Add object at 0x00000237DEAC4908>, <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x00000237DEACE608>, <tensorflow.python.keras.layers.core.Dense object at 0x00000237DEAD50C8>]\n"
     ]
    }
   ],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"sparse\"\n",
    "    generator = ImageDataGenerator(preprocessing_function=preprocess_image,\n",
    "                                   validation_split=0.001)\n",
    "    \n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    \n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net: \"code/sphereface_model.prototxt\"\n",
    "# #test_iter: 100 \n",
    "# #test_interval: 2000\n",
    "\n",
    "# base_lr: 0.1\n",
    "# lr_policy: \"multistep\"\n",
    "# gamma: 0.1\n",
    "\n",
    "# stepvalue: 16000\n",
    "# stepvalue: 24000\n",
    "# stepvalue: 28000\n",
    "# max_iter: 28000\n",
    "\n",
    "# display: 100\n",
    "# momentum: 0.9\n",
    "# weight_decay: 0.0005\n",
    "# #snapshot: 1000\n",
    "# snapshot_prefix: \"result/sphereface_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.001,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "# optimizer_ = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "optimizer_ = RMSprop(learning_rate=0.01, rho=0.9, epsilon=1e-07)\n",
    "# loss_ = custom_loss\n",
    "# loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer_, metrics=[accuracy])\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-678af381a018>:5: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Found 46982605 validated image filenames belonging to 2 classes.\n",
      "Found 46982605 validated image filenames belonging to 2 classes.\n",
      "    470/Unknown - 1699s 4s/step - loss: nan - accuracy: 0.5037"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-678af381a018>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://github.com/keras-team/keras/issues/10855\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1477\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1478\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1479\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1481\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_ = 32\n",
    "epochs_ = 1\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "hist = model.fit(train_generator(train_dataframe, batch_size_), epochs=epochs_, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3584/Unknown - 12768s 4s/step - loss: 5106773504.0000 - accuracy: 0.5556\n",
    "4824/Unknown - 17137s 4s/step - loss: 3794087168.0000 - accuracy: 0.5598          \n",
    "4903/Unknown - 17433s 4s/step - loss: 3732954624.0000 - accuracy: 0.5601  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fileL': '0004921\\\\045.jpg', 'fileR': '0004921\\\\124.jpg', 'flag': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casia_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "short test dataframe\n",
      "                                       fileL  \\\n",
      "0         Abel_Pacheco\\Abel_Pacheco_0001.jpg   \n",
      "1     Akhmed_Zakayev\\Akhmed_Zakayev_0001.jpg   \n",
      "2     Akhmed_Zakayev\\Akhmed_Zakayev_0002.jpg   \n",
      "3       Amber_Tamblyn\\Amber_Tamblyn_0001.jpg   \n",
      "4     Angela_Bassett\\Angela_Bassett_0001.jpg   \n",
      "...                                      ...   \n",
      "1195      Bob_Menendez\\Bob_Menendez_0001.jpg   \n",
      "1196            Bob_Riley\\Bob_Riley_0001.jpg   \n",
      "1197            Bob_Riley\\Bob_Riley_0001.jpg   \n",
      "1198            Bob_Riley\\Bob_Riley_0001.jpg   \n",
      "1199            Brad_Wilk\\Brad_Wilk_0001.jpg   \n",
      "\n",
      "                                           fileR  flag  \n",
      "0             Abel_Pacheco\\Abel_Pacheco_0004.jpg     1  \n",
      "1         Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "2         Akhmed_Zakayev\\Akhmed_Zakayev_0003.jpg     1  \n",
      "3           Amber_Tamblyn\\Amber_Tamblyn_0002.jpg     1  \n",
      "4         Angela_Bassett\\Angela_Bassett_0005.jpg     1  \n",
      "...                                          ...   ...  \n",
      "1195        Lauren_Hutton\\Lauren_Hutton_0001.jpg     0  \n",
      "1196            Danny_Ainge\\Danny_Ainge_0001.jpg     0  \n",
      "1197  Nastassia_Kinski\\Nastassia_Kinski_0002.jpg     0  \n",
      "1198  Sheila_Wellstone\\Sheila_Wellstone_0002.jpg     0  \n",
      "1199              Phil_Cline\\Phil_Cline_0001.jpg     0  \n",
      "\n",
      "[1200 rows x 3 columns]\n",
      "\n",
      "short train dataframe\n",
      "                fileL            fileR  flag\n",
      "0     0004921\\045.jpg  0004921\\124.jpg     1\n",
      "1     0913587\\204.jpg  0852965\\015.jpg     0\n",
      "2     0911320\\067.jpg  0911320\\082.jpg     1\n",
      "3     0316933\\022.jpg  2518732\\002.jpg     0\n",
      "4     0010075\\075.jpg  0254862\\003.jpg     0\n",
      "...               ...              ...   ...\n",
      "1195  1738059\\010.jpg  1738059\\067.jpg     1\n",
      "1196  2526306\\110.jpg  2526306\\146.jpg     1\n",
      "1197  0068338\\352.jpg  0068338\\365.jpg     1\n",
      "1198  0000439\\318.jpg  0000439\\369.jpg     1\n",
      "1199  0757855\\078.jpg  0757855\\226.jpg     1\n",
      "\n",
      "[1200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "casia_pairs_short = []\n",
    "lfw_pairs_short = []\n",
    "\n",
    "i_0 = 0 # number of pairs with 'flag' == 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(casia_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "\n",
    "i_0 = 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(lfw_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < 600:\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= 1200:\n",
    "        break\n",
    "        \n",
    "# convert to pandas dataframe\n",
    "test_dataframe_short = pd.DataFrame(lfw_pairs_short)\n",
    "train_dataframe_short = pd.DataFrame(casia_pairs_short) # takes long time\n",
    "\n",
    "print(\"short test dataframe\")\n",
    "print(test_dataframe_short)\n",
    "print()\n",
    "print(\"short train dataframe\")\n",
    "print(train_dataframe_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe_short['flag'] = train_dataframe_short['flag'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"binary\"\n",
    "    generator = ImageDataGenerator(preprocessing_function=preprocess_image,\n",
    "                                   validation_split=0.01)\n",
    "    \n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    \n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "# optimizer_ = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "optimizer_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "# loss_ = custom_loss\n",
    "# loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer_, metrics=[accuracy])\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1188 validated image filenames belonging to 2 classes.\n",
      "Found 1188 validated image filenames belonging to 2 classes.\n",
      "   5536/Unknown - 20088s 4s/step - loss: 14775679.0000 - accuracy: 0.8585"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-ae07734c903e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# https://github.com/keras-team/keras/issues/10855\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataframe_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size_ = 32\n",
    "epochs_ = 1\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "hist = model.fit(train_generator(train_dataframe_short, batch_size_), epochs=epochs_, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10/Unknown - 36s 4s/step - loss: 7992349696.0000 - accuracy: 0.5125\n",
    "25/Unknown - 97s 4s/step - loss: 3196939776.0000 - accuracy: 0.5163\n",
    "40/Unknow - 153s 4s/step - loss: 2042772992.0000 - accuracy: 0.5023\n",
    "130/Unknow - 509s 4s/step - loss: 627466112.0000 - accuracy: 0.5067\n",
    "252/Unknown - 1014s 4s/st - loss: 323904736.0000 - accuracy: 0.5089\n",
    "5271/Unknown - 19031s 4s/s - loss: 15518372.0000 - accuracy: 0.8516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10/Unknown - 36s 4s/step - loss: 7992349696.0000 - accuracy: 0.5125\n",
    "25/Unknown - 97s 4s/step - loss: 3196939776.0000 - accuracy: 0.5163\n",
    "40/Unknow - 153s 4s/step - loss: 2042772992.0000 - accuracy: 0.5023\n",
    "130/Unknow - 509s 4s/step - loss: 627466112.0000 - accuracy: 0.5067\n",
    "252/Unknown - 1014s 4s/st - loss: 323904736.0000 - accuracy: 0.5089\n",
    "5271/Unknown - 19031s 4s/s - loss: 15518372.0000 - accuracy: 0.8516"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_generator(train_dataframe, batch_size):\n",
    "    generator = ImageDataGenerator(\n",
    "                             fill_mode=\"nearest\",\n",
    "                             cval=0.0,\n",
    "                             horizontal_flip=False,\n",
    "                             vertical_flip=False,\n",
    "                             rescale=None,\n",
    "                             preprocessing_function=preprocess_image,\n",
    "                             data_format=None,\n",
    "                             validation_split=0.001,\n",
    "                             dtype=None)\n",
    "    \n",
    "    valid_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))  \n",
    "\n",
    "    valid_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=\"./data/CASIA-WebFace-112x96/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"validation\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = valid_generator_X1.next()\n",
    "        X2i = valid_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n",
    "\n",
    "\n",
    "\n",
    "def test_generator(test_dataframe, batch_size):\n",
    "    test_datagen = ImageDataGenerator(\n",
    "                             preprocessing_function=preprocess_image) \n",
    "    test_generator_X1 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(datasets_path / 'datasets' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "\n",
    "    test_generator_X2 = test_datagen.flow_from_dataframe(\n",
    "                             dataframe=test_dataframe,\n",
    "                             directory=str(datasets_path / 'datasets' / 'lfw_112x96'),\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             batch_size=batch_size,\n",
    "                             seed=42,\n",
    "                             shuffle=False,\n",
    "                             class_mode=class_mode_,\n",
    "                             target_size=(112,96))\n",
    "    while True:\n",
    "        X1i = test_generator_X1.next()\n",
    "        X2i = test_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2data(dt, dataset_path):\n",
    "    fileL_paths = list(map(lambda x: str(dataset_path / x), dt['fileL'].to_list()))\n",
    "    fileR_paths = list(map(lambda x: str(dataset_path / x), dt['fileR'].to_list()))\n",
    "    Y = list(map(lambda x: int(x), dt['flag'].to_list()))\n",
    "    \n",
    "    X1 = []\n",
    "    for path in fileL_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X1.append(image)\n",
    "    \n",
    "    X2 = []   \n",
    "    for path in fileR_paths:\n",
    "        image = cv2.imread(path)\n",
    "        image = preprocess_image(image)\n",
    "        X2.append(image)\n",
    "    \n",
    "    return [X1, X2], Y\n",
    "\n",
    "X, Y = dataframe2data(train_dataframe, train_dataset_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0][0].shape)\n",
    "# print(X[0][0])\n",
    "plt.imshow(X[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset_path / casia_pairs[0]['fileL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "X1 = []\n",
    "X2 = []\n",
    "Y = []\n",
    "for pair in tqdm(casia_pairs_short):\n",
    "    imageL = cv2.imread(str(train_dataset_path / pair['fileL']))\n",
    "    imageL = preprocess_image(imageL)\n",
    "    imageR = cv2.imread(str(train_dataset_path / pair['fileR']))\n",
    "    imageR = preprocess_image(imageR)\n",
    "    X1.append(imageL)\n",
    "    X2.append(imageR)\n",
    "    Y.append(pair['flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.asarray(X1)\n",
    "X2 = np.asarray(X2)\n",
    "Y = np.asarray(Y)\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "batch_size_ = 64\n",
    "epochs_ = 6\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "rms_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])\n",
    "# model.compile(loss=contrastive_loss, optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "\n",
    "def generator_two_img(X1, X2, y, batch_size):\n",
    "    generator = ImageDataGenerator()\n",
    "    \n",
    "    genX1 = generator.flow(X1, y,  batch_size=batch_size, seed=1)\n",
    "    genX2 = generator.flow(X2, y, batch_size=batch_size, seed=1)\n",
    "    while True:\n",
    "        X1i = genX1.next()\n",
    "        X2i = genX2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(generator_two_img(X1, X2, Y, batch_size_),\n",
    "                           steps_per_epoch=len(X1)//batch_size_, \n",
    "                           epochs=epochs_,\n",
    "                           callbacks = None, \n",
    "                           shuffle=True)\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "# hist = model.fit(X, Y, epochs=epochs_, batch_size=batch_size_)\n",
    "# hist = model.fit(x=X, \n",
    "#                  y=Y, \n",
    "#                  batch_size=batch_size_, \n",
    "#                  epochs=epochs_, \n",
    "#                  verbose=1, \n",
    "#                  callbacks=None,\n",
    "#                  validation_split=0.01, \n",
    "#                  validation_data=None, \n",
    "#                  shuffle=True, \n",
    "#                  class_weight=None,\n",
    "#                  sample_weight=None, \n",
    "#                  initial_epoch=0, \n",
    "#                  steps_per_epoch=None,\n",
    "#                  validation_steps=None, \n",
    "#                  validation_batch_size=None, \n",
    "#                  validation_freq=1,\n",
    "#                  max_queue_size=10, \n",
    "#                  workers=1, \n",
    "#                  use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[0].shape, X2[0].shape, Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_test = np.expand_dims(X1[0], 0)\n",
    "X2_test = np.expand_dims(X2[0], 0)\n",
    "print(X1_test.shape, X2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "prediction = base_network.predict(X1_test)\n",
    "print(prediction.shape)\n",
    "# print(prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_network.layers:\n",
    "    print(layer.output_shape, layer.name)\n",
    "    \n",
    "print(base_network.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "input_shape = x_train.shape[1:]\n",
    "print(\"input shape: \", input_shape)\n",
    "\n",
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import random\n",
    "# from keras.datasets import mnist\n",
    "# from keras.models import Model\n",
    "# from keras.optimizers import RMSprop\n",
    "# from keras import backend as K\n",
    "\n",
    "# num_classes = 10\n",
    "# epochs = 20\n",
    "\n",
    "\n",
    "# def euclidean_distance(vects):\n",
    "#     x, y = vects\n",
    "#     sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "#     return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "# def eucl_dist_output_shape(shapes):\n",
    "#     shape1, shape2 = shapes\n",
    "#     return (shape1[0], 1)\n",
    "\n",
    "\n",
    "# def contrastive_loss(y_true, y_pred):\n",
    "#     '''Contrastive loss from Hadsell-et-al.'06\n",
    "#     http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "#     '''\n",
    "#     margin = 1\n",
    "#     square_pred = K.square(y_pred)\n",
    "#     margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "#     return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "# def create_pairs(x, digit_indices):\n",
    "#     '''Positive and negative pair creation.\n",
    "#     Alternates between positive and negative pairs.\n",
    "#     '''\n",
    "#     pairs = []\n",
    "#     labels = []\n",
    "#     n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "#     for d in range(num_classes):\n",
    "#         for i in range(n):\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             inc = random.randrange(1, num_classes)\n",
    "#             dn = (d + inc) % num_classes\n",
    "#             z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "#             pairs += [[x[z1], x[z2]]]\n",
    "#             labels += [1, 0]\n",
    "#     return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "# def compute_accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     pred = y_pred.ravel() < 0.5\n",
    "#     return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#     '''Compute classification accuracy with a fixed threshold on distances.\n",
    "#     '''\n",
    "#     return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# # the data, split between train and test sets\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_test = x_test.astype('float32')\n",
    "# x_train /= 255\n",
    "# x_test /= 255\n",
    "# input_shape = x_train.shape[1:]\n",
    "\n",
    "# # create training+test positive and negative pairs\n",
    "# digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "# tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "# digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "# te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# # network definition\n",
    "# base_network = create_base_network(input_shape)\n",
    "\n",
    "# input_a = Input(shape=input_shape)\n",
    "# input_b = Input(shape=input_shape)\n",
    "\n",
    "# # because we re-use the same instance `base_network`,\n",
    "# # the weights of the network\n",
    "# # will be shared across the two branches\n",
    "# processed_a = base_network(input_a)\n",
    "# processed_b = base_network(input_b)\n",
    "\n",
    "# distance = Lambda(euclidean_distance,\n",
    "#                   output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "# model = Model([input_a, input_b], distance)\n",
    "\n",
    "# # train\n",
    "# rms = RMSprop()\n",
    "# model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "# model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "#           batch_size=128,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# # compute final accuracy on training and test sets\n",
    "# y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "# tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "# y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "# te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "# print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "# print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
