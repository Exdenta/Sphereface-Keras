{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress Tensorflow verbose prints\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from form_train_data import load_data\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import spatial\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "data_path = Path.cwd().parent / 'datasets'\n",
    "train_dataset_path = data_path / 'CASIA-WebFace-112x96'\n",
    "pairs_count = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CASIA pairs for training\")\n",
    "print(\"LFW pairs for testing\")\n",
    "casia_pairs, lfw_pairs = load_data(data_path)\n",
    "\n",
    "print(\"shuffle casia list\")\n",
    "np.random.shuffle(casia_pairs)\n",
    "\n",
    "casia_pairs_short = []\n",
    "lfw_pairs_short = []\n",
    "\n",
    "i_0 = 0 # number of pairs with 'flag' == 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(casia_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < (pairs_count // 2):\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < (pairs_count // 2):\n",
    "        casia_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= pairs_count:\n",
    "        break\n",
    "\n",
    "i_0 = 0\n",
    "i_1 = 0\n",
    "for i, pair in enumerate(lfw_pairs):\n",
    "    if pair['flag'] == 0 and i_0 < (pairs_count // 2):\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_0 += 1\n",
    "    elif pair['flag'] == 1 and i_1 < (pairs_count // 2):\n",
    "        lfw_pairs_short.append(pair)\n",
    "        i_1 += 1\n",
    "    if (i_0 + i_1) >= pairs_count:\n",
    "        break\n",
    "        \n",
    "# convert to pandas dataframe\n",
    "test_dataframe_short = pd.DataFrame(lfw_pairs_short)\n",
    "train_dataframe_short = pd.DataFrame(casia_pairs_short) # takes long time\n",
    "\n",
    "train_dataframe_short['flag'] = train_dataframe_short['flag'].astype(str)\n",
    "\n",
    "print(\"short test dataframe\")\n",
    "print(test_dataframe_short)\n",
    "print()\n",
    "print(\"short train dataframe\")\n",
    "print(train_dataframe_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"binary\"\n",
    "    generator = ImageDataGenerator(preprocessing_function=preprocess_image,\n",
    "                                   validation_split=0.01)\n",
    "    \n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileL\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    \n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "                             dataframe=train_dataframe,\n",
    "                             directory=str(train_dataset_path) + \"/\",\n",
    "                             x_col=\"fileR\",\n",
    "                             y_col=\"flag\",\n",
    "                             subset=\"training\",\n",
    "                             batch_size=batch_size_,\n",
    "                             seed=42,\n",
    "                             shuffle=True,\n",
    "                             class_mode=class_mode_,\n",
    "                             color_mode='rgb',\n",
    "                             target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Add, Activation, PReLU, Dense, Input, ZeroPadding2D, Lambda, GlobalAveragePooling2D, Dot \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CosineSimilarity\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# from keras.engine.topology import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "\n",
    "def conv_3_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=2, padding='valid', kernel_initializer='glorot_uniform')(x)\n",
    "    r1 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r1)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r2 = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(r2)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    r3 = PReLU()(x)\n",
    "\n",
    "    x = Add()([r1, r3])\n",
    "    return x \n",
    "\n",
    "def conv_2_block(input, filters):\n",
    "    x = ZeroPadding2D(padding=(1, 1))(input)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = Conv2D(filters, 3, strides=1, padding='valid', kernel_initializer=TruncatedNormal(stddev=0.01))(x)\n",
    "    x = PReLU()(x)\n",
    "\n",
    "    x = Add()([input, x])\n",
    "    return x\n",
    "\n",
    "def sphereface20(input_shape):\n",
    "    input = Input(shape=input_shape)\n",
    "    x = conv_3_block(input, 64)\n",
    "    x = conv_3_block(x, 128)\n",
    "    x = conv_2_block(x, 128)\n",
    "    x = conv_3_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_2_block(x, 256)\n",
    "    x = conv_3_block(x, 512)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, kernel_initializer='glorot_uniform')(x)\n",
    "    \n",
    "    model = Model(input, x)\n",
    "    return model\n",
    "\n",
    "# https://keras.io/examples/mnist_siamese/\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "# https://stackoverflow.com/questions/51003027/computing-cosine-similarity-between-two-tensors-in-keras\n",
    "def cosine_distance(vests):\n",
    "    x, y = vests\n",
    "    x = K.l2_normalize(x, axis=-1)\n",
    "    y = K.l2_normalize(y, axis=-1)\n",
    "    return -K.mean(x * y, axis=-1, keepdims=True)\n",
    "\n",
    "def cos_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0],1)\n",
    "\n",
    "\n",
    "# network definition\n",
    "input_shape = (112, 96, 3)\n",
    "base_network = sphereface20(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# serialize model to JSON\n",
    "model_path = str(Path.cwd().parent / 'models' / 'sphereface_20_keras' / 'sphereface_20.json')\n",
    "model_json = base_network.to_json()\n",
    "with open(model_path, \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def custom_loss(yTrue,yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "# def cosine_similarity(y_true, y_pred):\n",
    "#     y = tf.constant([c1,c2])\n",
    "#     x = K.l2_normalize(y_true, -1)\n",
    "#     y = K.l2_normalize(y_pred, -1)\n",
    "#     s = K.mean(x * y, axis=-1, keepdims=False) * 10\n",
    "#     return s\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    0.0001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "# optimizer_ = keras.optimizers.SGD(learning_rate=lr_schedule)\n",
    "\n",
    "# rms_ = RMSprop()\n",
    "optimizer_ = RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-07)\n",
    "# loss_ = custom_loss\n",
    "# loss_ = CosineSimilarity(axis=-1, name='cosine_similarity')\n",
    "\n",
    "model.compile(loss=contrastive_loss, optimizer=optimizer_, metrics=[accuracy])\n",
    "# model.compile(loss=loss_, optimizer=rms_, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_ = 32\n",
    "epochs_ = 1\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/10855\n",
    "hist = model.fit(train_generator(train_dataframe_short, batch_size_), epochs=epochs_, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
