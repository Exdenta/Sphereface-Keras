{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-b41ee552b666>:30: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Loading data\n",
      "Loading test data\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\Projects\\Face_Identification\\sphereface_keras\\margin_inner_product_layer.py:49 call  *\n        x1 = K.variable(value=x1)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:845 variable  **\n        constraint=constraint)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:261 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:255 _variable_v2_call\n        shape=shape)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:236 <lambda>\n        previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2647 default_variable_creator_v2\n        shape=shape)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:263 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1434 __init__\n        distribute_strategy=distribute_strategy)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1517 _init_from_args\n        raise ValueError(\"Tensor-typed variable initializers must either be \"\n\n    ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b41ee552b666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    180\u001b[0m     mode='auto')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_train_2_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[0msave_model_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sphereface_20.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Face_Identification\\sphereface_keras\\models.py\u001b[0m in \u001b[0;36mget_train_2_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;31m# network definition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m112\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m96\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m     \u001b[0mbase_network\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msphereface20\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[0minput_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Projects\\Face_Identification\\sphereface_keras\\models.py\u001b[0m in \u001b[0;36msphereface20\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mfc6\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMarginInnerProductLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\Projects\\Face_Identification\\sphereface_keras\\margin_inner_product_layer.py:49 call  *\n        x1 = K.variable(value=x1)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:845 variable  **\n        constraint=constraint)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:261 __call__\n        return cls._variable_v2_call(*args, **kwargs)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:255 _variable_v2_call\n        shape=shape)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:236 <lambda>\n        previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py:2647 default_variable_creator_v2\n        shape=shape)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py:263 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1434 __init__\n        distribute_strategy=distribute_strategy)\n    d:\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1517 _init_from_args\n        raise ValueError(\"Tensor-typed variable initializers must either be \"\n\n    ValueError: Tensor-typed variable initializers must either be wrapped in an init_scope or callable (e.g., `tf.Variable(lambda : tf.truncated_normal([10, 40]))`) when building functions. Please file a feature request if this restriction inconveniences you.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from utils import load_data, load_short_train_data, load_test_data\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from models import get_train_2_model, save_model_config\n",
    "from tensorflow.keras.losses import CosineSimilarity\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from scipy import spatial\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "# suppress Tensorflow verboget_train_modelse prints\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "tf.test.is_gpu_available()\n",
    "\n",
    "# https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/\n",
    "# https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c\n",
    "# https://stackoverflow.com/questions/49404993/keras-how-to-use-fit-generator-with-multiple-inputs\n",
    "\n",
    "data_path = Path.cwd() / 'datasets'\n",
    "train_dataset_path = data_path / 'CASIA-WebFace-112x96'\n",
    "test_dataset_path = data_path / 'lfw_112x96'\n",
    "\n",
    "print(\"Loading data\")\n",
    "train_dataframe = np.load(\"datasets/casia_5000_pairs.npy\") # load_short_train_data(data_path, 5000)\n",
    "test_dataframe = load_test_data(data_path)\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = (image - 127.5) / 128\n",
    "    return image\n",
    "\n",
    "\n",
    "def train_generator(train_dataframe, batch_size_):\n",
    "    class_mode_ = \"binary\"\n",
    "    generator = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_image, validation_split=0.0)\n",
    "\n",
    "    train_generator_X1 = generator.flow_from_dataframe(\n",
    "        dataframe=train_dataframe,\n",
    "        directory=str(train_dataset_path) + \"/\",\n",
    "        x_col=\"fileL\",\n",
    "        y_col=\"flag\",\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size_,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=class_mode_,\n",
    "        color_mode='rgb',\n",
    "        target_size=(112, 96))\n",
    "\n",
    "    train_generator_X2 = generator.flow_from_dataframe(\n",
    "        dataframe=train_dataframe,\n",
    "        directory=str(train_dataset_path) + \"/\",\n",
    "        x_col=\"fileR\",\n",
    "        y_col=\"flag\",\n",
    "        subset=\"training\",\n",
    "        batch_size=batch_size_,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=class_mode_,\n",
    "        color_mode='rgb',\n",
    "        target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = train_generator_X1.next()\n",
    "        X2i = train_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n",
    "\n",
    "\n",
    "def test_generator(test_dataframe, batch_size):\n",
    "    class_mode_ = \"binary\"\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_image)\n",
    "    test_generator_X1 = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_dataframe,\n",
    "        directory=str(test_dataset_path) + \"/\",\n",
    "        x_col=\"fileL\",\n",
    "        y_col=\"flag\",\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode=class_mode_,\n",
    "        color_mode='rgb',\n",
    "        target_size=(112, 96))\n",
    "\n",
    "    test_generator_X2 = test_datagen.flow_from_dataframe(\n",
    "        dataframe=test_dataframe,\n",
    "        directory=str(test_dataset_path) + \"/\",\n",
    "        x_col=\"fileR\",\n",
    "        y_col=\"flag\",\n",
    "        batch_size=batch_size,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode=class_mode_,\n",
    "        color_mode='rgb',\n",
    "        target_size=(112, 96))\n",
    "    while True:\n",
    "        X1i = test_generator_X1.next()\n",
    "        X2i = test_generator_X2.next()\n",
    "        yield [X1i[0], X2i[0]], X1i[1]\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def custom_loss(yTrue, yPred):\n",
    "    return K.sum(K.log(yTrue) - K.log(yPred))\n",
    "\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = [1, 1]\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        sd.append(step_decay(len(self.losses)))\n",
    "        print(', lr:', step_decay(len(self.losses)))\n",
    "\n",
    "\n",
    "sd = []\n",
    "\n",
    "learning_rate = 0.0001\n",
    "decay_rate = 5e-6\n",
    "momentum = 0.9\n",
    "batch_size_ = 32\n",
    "images_per_epoch_ = 100000\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate,\n",
    "                           momentum=momentum,\n",
    "                           decay=decay_rate,\n",
    "                           nesterov=False)\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    momentum = 0.8\n",
    "    decay_rate = 2e-6\n",
    "    lr = learning_rate\n",
    "    return lr\n",
    "\n",
    "\n",
    "def step_decay(losses):\n",
    "    lrate = learning_rate\n",
    "    momentum = 0.8\n",
    "    decay_rate = 2e-6\n",
    "    return lrate\n",
    "\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=1,\n",
    "    verbose=0,\n",
    "    mode='auto')\n",
    "\n",
    "model = get_train_2_model()\n",
    "save_model_config('sphereface_20.json')\n",
    "\n",
    "\n",
    "history = LossHistory()\n",
    "lrate = keras.callbacks.LearningRateScheduler(scheduler)\n",
    "callbacks_ = [history, lrate, early_stopping]\n",
    "initial_epoch_ = 1\n",
    "epochs_ = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=contrastive_loss,\n",
    "              optimizer=sgd,\n",
    "              metrics=[accuracy])\n",
    "\n",
    "weights_path = str(folder_path / 'sphereface_20_8372.h5')\n",
    "model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_generator(train_dataframe, batch_size_),\n",
    "                 steps_per_epoch=images_per_epoch_ // batch_size_,\n",
    "                 epochs=epochs_,\n",
    "                 validation_data=test_generator(test_dataframe, batch_size_),\n",
    "                 validation_steps=len(test_dataframe) // batch_size_,\n",
    "                 callbacks=callbacks_,\n",
    "                 initial_epoch=initial_epoch_,\n",
    "                 shuffle=True)\n",
    "\n",
    "save_path = str(folder_path / 'sphereface_20_new.h5')\n",
    "model.save_weights(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
